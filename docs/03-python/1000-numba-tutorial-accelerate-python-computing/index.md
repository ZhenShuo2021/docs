---
title: Numba æ•™å­¸ï¼šåŠ é€Ÿ Python ç§‘å­¸è¨ˆç®—
description: æœ€å¿«ã€æœ€æ­£ç¢ºã€æœ€å®Œæ•´çš„ Numba æ•™å­¸ï¼šä½¿ç”¨ Numba åŠ é€Ÿ Python ç§‘å­¸è¨ˆç®—ã€‚å‘ç­†è€…éƒ½è¸©éäº†åªè¦ç…§åšå¯ä»¥å¾—åˆ°æœ€å¥½æ€§èƒ½ï¼Œä¸æœƒæ¼æ‰ä»»ä½•å„ªåŒ–å¯èƒ½ï¼›é™¤æ­¤ä¹‹å¤–æœ¬æ–‡ç¬¬ä¸€ä¸å»¢è©±ï¼Œç¬¬äºŒä¸Šæ‰‹æ¥µå¿«ï¼Œç¬¬ä¸‰ä»‹ç´¹å¦‚ä½•é™¤éŒ¯å’Œå„ªåŒ–ï¼Œç¬¬å››è£œå……é€²éšä½¿ç”¨æ–¹å¼ï¼Œç¬¬äº”çµ¦å‡ºã€Œç²¾é¸æœ‰ç”¨çš„å»¶ä¼¸é–±è®€ã€ï¼Œä¸æ˜¯çµ¦æ²’ç”¨æ–‡ç« ï¼Œç¬¬å…­ä¹Ÿæ˜¯æœ€é‡è¦ï¼Œç­†è€…å¯ä»¥å¾ˆè‡ªä¿¡çš„èªªæœ¬æ–‡æ˜¯ä¸­æ–‡åœˆæœ€è©³ç´°æ•™å­¸ã€‚
tags:
  - Programming
  - Python
  - Numba
  - Performance
  - æ•™å­¸
keywords:
  - Programming
  - Python
  - Numba
  - Numpy
  - æ•™å­¸
  - Speed-Up
  - Accelerate
  - Performance
last_update:
  date: 2024-10-03 GMT+8
  author: zsl0621
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Numba æ•™å­¸ï¼šåŠ é€Ÿ Python ç§‘å­¸è¨ˆç®—
é‘‘æ–¼ç¹é«”ä¸­æ–‡è³‡è¨Šå°‘ï¼Œæœ€è¿‘å‰›å¥½åˆé‡çœ‹äº†ä¸€ä¸‹æ–‡æª”ï¼Œæ–¼æ˜¯æ•´ç†è³‡è¨Šåˆ†äº«çµ¦å¤§å®¶ã€‚æœ¬ç¯‡çš„ç›®æ¨™è®€è€…æ˜¯æ²’å­¸éè¨ˆç®—æ©Ÿçš„åˆéšç”¨æˆ¶åˆ°ä¸­éšç”¨æˆ¶éƒ½å¯ä»¥è®€ï¼Œç­†è€…èƒ½ä¿è­‰é€™ç¯‡çµ•å°æ˜¯ä½ èƒ½æ‰¾åˆ°æœ€å¥½çš„æ•™å­¸ï¼Œæœ¬æ•™å­¸å·²ç¶“è¦†è“‹åˆ°é™¤äº† CUDA ä»¥å¤–çš„æ‰€æœ‰ä½¿ç”¨æ–¹å¼ï¼Œå°æ–¼ CUDA æœ¬æ–‡ç›´æ¥æä¾›æ›´å¥½çš„æ•™å­¸é€£çµã€‚

- **ç‚ºç”šéº¼é¸æ“‡æ­¤æ•™å­¸**  
    >æœ€å¿«ã€æœ€æ­£ç¢ºã€æœ€å®Œæ•´[^feature]   
    
    å‘ç­†è€…éƒ½è¸©éäº†åªè¦ç…§åšå¯ä»¥å¾—åˆ°æœ€å¥½æ€§èƒ½ï¼Œä¸æœƒæ¼æ‰ä»»ä½•å„ªåŒ–å¯èƒ½ï¼›é™¤æ­¤ä¹‹å¤–æœ¬æ–‡ç¬¬ä¸€ä¸å»¢è©±ï¼Œç¬¬äºŒä¸Šæ‰‹æ¥µå¿«ï¼Œç¬¬ä¸‰ä»‹ç´¹å¦‚ä½•é™¤éŒ¯å’Œå„ªåŒ–ï¼Œç¬¬å››è£œå……é€²éšä½¿ç”¨æ–¹å¼ï¼Œç¬¬äº”çµ¦å‡ºç²¾é¸çš„å»¶ä¼¸é–±è®€ã€‚

[^feature]: å°æ–¼åˆéšä½¿ç”¨è€…ï¼Œæœ¬æ–‡æ˜ç¢ºèªªæ˜éœ€è¦é–±è®€çš„ç« ç¯€ä»¥å…æ¨¡ä¹ç„¦é»ï¼›å°æ–¼ä¸­é«˜éšä½¿ç”¨è€…ï¼Œæœ¬æ–‡å°å¹³è¡ŒåŒ–æˆ– vectorize ç­‰é«˜ç´šä½¿ç”¨æŠ€å·§ä¹Ÿæœ‰è©³ç´°èªªæ˜ï¼Œä¸¦ä¸”å°ç¶²è·¯æ–‡ç« ä¸­çš„**è«¸å¤šéŒ¯èª¤**åšå‡ºå‹˜èª¤å’Œå¯¦æ¸¬ã€‚

- **å¦‚ä½•é–±è®€æœ¬æ–‡**  
    æœ¬æ–‡æ ¹æ“šå®˜æ–¹æ–‡æª”é‡æ–°ç·¨æ’ï¼Œé‚è¼¯ç”±å¸¸ç”¨åˆ°å°‘ç”¨ï¼Œä½¿ç”¨æ–¹å¼ç°¡å–®åˆ°è¤‡é›œï¼Œæ•ˆèƒ½æå‡å¹…åº¦ç”±é«˜åˆ°ä½ã€‚  

    ä¸ç”¨å®³æ€•æ–‡ç« çœ‹ä¼¼å¾ˆé•·ï¼Œåˆå­¸è€…åªéœ€çœ‹<u>åŸºç¤ä½¿ç”¨</u>å³å¯æŒæ¡çµ•å¤§å¤šæ•¸ä½¿ç”¨æƒ…å¢ƒï¼›é‚„è¦æ›´å¿«å†çœ‹<u>è‡ªå‹•å¹³è¡ŒåŒ–èˆ‡ç«¶çˆ­å±å®³</u>ï¼›å°æ–¼å¤§å¤šæ•¸äººè€Œè¨€éƒ½ä¸ç”¨çœ‹<u>é€²éšä½¿ç”¨</u>ï¼›å¦‚æœä½ æ€¥åˆ°ä¸è¡Œï¼Œçœ‹å®Œ<u>ä¸€åˆ†é˜å­¸æœƒ Numba</u> å¾Œç›´æ¥çœ‹<u>å°çµ</u>ã€‚


:::info å¯«åœ¨å‰é¢

ä¸è¦çœ‹ [**èˆŠç‰ˆ**ï¼Œå·¦ä¸Šè§’ç‰ˆæœ¬è™Ÿ 0.52](https://numba.pydata.org/) çš„æ–‡æª”ï¼å…§å®¹ç¼ºå¤±ï¼ŒååèˆŠç‰ˆæ–‡æª” Google æœå°‹åœ¨å‰é¢ï¼Œä¸€ä¸å°å¿ƒå°±é»é€²å»äº†ã€‚

:::

## ç°¡ä»‹ï¼šNumba æ˜¯ä»€éº¼ï¼Ÿ
Numba æ˜¯ä¸€å€‹å°‡ Python å’Œ Numpy ç¨‹å¼ç¢¼è½‰æ›ç‚ºå¿«é€Ÿçš„æ©Ÿå™¨ç¢¼çš„å³æ™‚ç·¨è­¯å™¨ (Just-In-Time Compiler, JIT)ã€‚

Python ä¹‹æ‰€ä»¥æ…¢çš„åŸå› æ˜¯èº«ç‚ºå‹•æ…‹èªè¨€ï¼Œåœ¨é‹è¡Œæ™‚éœ€è¦é¡å¤–é–‹éŠ·ä¾†é€²è¡Œé¡å‹æª¢æŸ¥ï¼Œé‚„éœ€è¦è½‰è­¯æˆå­—ç¯€ç¢¼åœ¨è™›æ“¬æ©Ÿä¸ŠåŸ·è¡Œï¼Œæ›´æœ‰ GIL é€²ä¸€æ­¥é™åˆ¶æ•ˆèƒ½ï¼ˆè¦‹[é™„éŒ„](/docs/python/numba-tutorial-accelerate-python-computing#é™„éŒ„)ï¼‰ï¼Œæ–¼æ˜¯ Numba å°±é‡å°é€™äº›å•é¡Œä¾†è§£æ±ºï¼Œä»¥ä¸‹æ˜¯ä»–çš„ä¸»è¦ç‰¹è‰²ï¼š

- éœæ…‹é¡å‹æ¨æ–·ï¼šNumba åœ¨ç·¨è­¯æ™‚åˆ†æç¨‹å¼ç¢¼æ¨æ–·è®Šæ•¸é¡å‹ï¼Œé¿å…é¡å¤–çš„å‹åˆ¥æª¢æŸ¥ã€‚
- å³æ™‚ç·¨è­¯ï¼šå°‡ Python ç¨‹å¼ç¢¼ç·¨è­¯æˆå„ªåŒ–çš„æ©Ÿå™¨ç¢¼ã€‚
- å¹³è¡ŒåŒ–ï¼šNumba æ”¯æ´å¹³è¡Œè¨ˆç®—ã€‚
- å‘é‡åŒ–ï¼šåŸºæ–¼ LLVM (LLVM èª¿ç”¨ SIMD) å°‡è¿´åœˆä¸­æ“ä½œå‘é‡åŒ–ã€‚

## æˆ‘æ˜¯å¦è©²é¸æ“‡ Numbaï¼Ÿ

> Q: [å“ªäº›ç¨‹å¼é©åˆ Numba](https://numba.readthedocs.io/en/stable/user/5minguide.html#will-numba-work-for-my-code)  

å¤§é‡åŒ…å«è¿´åœˆçš„ Numpy æ•¸å€¼é‹ç®—ï¼Œä¸”ä¸æ¶‰åŠ I/O æ“ä½œï¼Œä¾‹å¦‚ pandasã€‚(If your code is numerically orientated (does a lot of math), uses NumPy a lot and/or has a lot of loops, then numba is often a good choice.)

> Q: Numba æœ‰ä»€éº¼ç‰¹é»ï¼Ÿ  

1. ç°¡å–®ï¼šåªè¦ä¸€è¡Œè£é£¾å™¨å°±å¯ä»¥åŠ é€Ÿç¨‹å¼ã€‚
2. å¿«é€Ÿï¼šå°ˆç‚ºç§‘å­¸è¨ˆç®—è€Œç”Ÿï¼Œè¢«è¨­è¨ˆæˆå’Œ Numpy å”åŒå·¥ä½œï¼ˆä½†ä¹Ÿå¯ä»¥åŠ é€Ÿ Python èªæ³•ï¼‰ã€‚
3. æ–¹ä¾¿ï¼šæ”¯æ´ **è‡ªå‹•** å¹³è¡ŒåŒ–è¨ˆç®—ï¼Œæ•ˆèƒ½æ¯” Python å¹³è¡ŒåŒ–[æ›´å¥½](/docs/python/numba-tutorial-accelerate-python-computing#è‡ªå‹•å¹³è¡ŒåŒ–)ã€‚
4. å¼·å¤§ï¼šæ”¯æ´ **CUDA** ä»¥é¡¯ç¤ºå¡åŸ·è¡Œé«˜åº¦å¹³è¡ŒåŒ–çš„è¨ˆç®—ã€‚
5. é€šç”¨ï¼šé™¤äº†å³æ™‚ç·¨è­¯ä¹Ÿæ”¯æ´æå‰ç·¨è­¯ï¼Œè®“ç¨‹å¼ç¢¼åœ¨æ²’æœ‰ Numba æˆ–è¦æ±‚é¦–æ¬¡åŸ·è¡Œé€Ÿåº¦çš„å ´æ™¯æ‡‰ç”¨ã€‚

> Q: å’Œç«¶çˆ­å“å¦‚ä½•é¸æ“‡ï¼Ÿ  

å¸¸è¦‹çš„ç«¶çˆ­é¸é …æœ‰ Cythonã€pybind11ã€Pythran å’Œ CuPyï¼Œæˆ‘å€‘å¾ç‰¹é»è¨è«–åˆ°æ€§èƒ½ï¼Œæœ€å¾Œåšå‡ºçµè«–ã€‚

- **ç‰¹é»**
    - Cythonï¼šéœ€è¦å­¸æœƒä»–çš„ç¨ç‰¹èªæ³•ï¼Œè©²èªæ³•åªèƒ½ç”¨åœ¨ Cythonã€‚
    - pybindï¼šå°±æ˜¯å¯« C++ã€‚
    - Pythranï¼šå’Œ Numba æ¥è¿‘ï¼Œä½†æ˜¯æ˜¯æå‰ç·¨è­¯ã€‚
    - Numbaï¼šåªæ”¯æ´ Numpyï¼Œä¸¦ä¸”æœ‰äº›èªæ³•ä¸æ”¯æ´ï¼Œå¦‚ [fft](https://numba.discourse.group/t/rocket-fft-a-numba-extension-supporting-numpy-fft-and-scipy-fft/1657) å’Œ[ç¨€ç–çŸ©é™£](https://numba-scipy.readthedocs.io/en/latest/reference/sparse.html)ã€‚
    - CuPyï¼šç‚ºäº† Numpy + Scipy è€Œç”Ÿçš„ CUDA GPU è¨ˆç®—å¥—ä»¶ã€‚

- **æ•ˆèƒ½**   
    å¾ [Python åŠ é€Ÿç¬¦æ–‡](https://stephlin.github.io/posts/Python/Python-speedup.html) é€™ç¯‡æ–‡ç« ä¸­æˆ‘å€‘å¯ä»¥çœ‹åˆ°æ•ˆèƒ½[^1]ç›¸å·®ä¸å¤§ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œä½ èƒ½ç¢ºå®šæ–‡ç« ä½œè€…çœŸçš„æœƒç”¨è©²å¥—ä»¶å—[^2]ï¼Ÿå°±åƒæˆ‘åœ¨å¯«é€™ç¯‡æ–‡ç« å‰ä¹Ÿä¸çŸ¥é“ Numba æœ‰é€™å€‹[é­”æ³•](/docs/python/numba-tutorial-accelerate-python-computing#guvectorize)ï¼Œç¶²è·¯ä¸Šä¹Ÿå¹¾ä¹æ²’æœ‰æ–‡ç« æåˆ°ã€‚  

    æ‰€ä»¥æˆ‘å€‘æ‡‰è©²è€ƒé‡çš„æ˜¯å¥—ä»¶æ˜¯å¦æœ‰é™åˆ¶å’Œå¯ç¶­è­·æ€§ï¼Œè€Œä¸æ˜¯è¿½æ±‚æœ€å¿«çš„æ•ˆèƒ½ï¼Œä¸ç„¶ä¸€é–‹å§‹å°±å¯« C ä¸å°±å¥½äº†ã€‚ä½†æ˜¯å¥—ä»¶çš„é™åˆ¶åœ¨ä½¿ç”¨ä¹‹å‰æ ¹æœ¬ä¸çŸ¥é“ï¼Œä¾‹å¦‚ Numba ä¸æ”¯æ´ç¨€ç–çŸ©é™£æˆ‘ä¹Ÿæ˜¯è¸©éå‘æ‰çŸ¥é“ï¼Œæ‰€ä»¥è€ƒé‡å°±å‰©ä¸‹ç¶­è­·æ€§äº†ï¼Œè€Œ Numba åœ¨å¯è®€æ€§å’ŒåµéŒ¯éƒ½æœ‰å¾ˆå¥½çš„è¡¨ç¾ã€‚
    
    å¦å¤–èˆ‡ Numba ç›¸ä¼¼çš„ Pythran æœå°‹çµæœåªæœ‰ä¸€è¬ç­†è³‡æ–™ï¼Œç­†è€…å°‡å…¶æ­¸é¡ç‚º othersï¼Œä¸è¦æŠ˜ç£¨è‡ªå·±ã€‚

- **çµè«–**  
    ç¶“éé€™äº›è¨è«–æˆ‘å€‘å¯ä»¥ç¸½çµæˆä»¥ä¸‹
    - Numbaï¼š**ç°¡å–®åˆå¿«**ã€‚é©ç”¨ä¸æœƒå¤ªå¤šç¨‹å¼å„ªåŒ–æŠ€å·§ï¼Œä¹Ÿä¸å¤ªæœƒç”¨åˆ°ä¸æ”¯æ´çš„å‡½å¼çš„ç”¨æˆ¶ã€‚é™¤æ­¤ä¹‹å¤–ä¹Ÿæ”¯æ´ CUDA è¨ˆç®—ã€‚
    - Cythonï¼šéº»ç…©åˆä¸è¦‹å¾—æ¯”è¼ƒå¿«ã€‚æœ€å¤§çš„å„ªé»ä¹Ÿæ˜¯å”¯ä¸€çš„å„ªé»æ˜¯æ”¯æ´æ›´å¤š Python èªæ³•ï¼Œä»¥åŠä½ å¸Œæœ›å°ç¨‹å¼æœ‰æ›´å¤šæ§åˆ¶ï¼ŒNumba å› ç‚ºå¤ªæ–¹ä¾¿æ‰€ä»¥é‹ä½œèµ·ä¾†ä¹Ÿåƒæ˜¯å€‹é»‘ç›’å­ï¼Œæœ‰æ™‚ä½ æœƒæ„Ÿåˆ°ä¸å®‰å¿ƒã€‚
    - pybindï¼šæ¥µé™æ€§èƒ½è¦æ±‚ã€‚
    - CuPyï¼šå¤§é‡å¹³è¡Œè¨ˆç®—ï¼Œéœ€è¦ CUDA è¨ˆç®—ã€‚

[^1]: å› ç‚º Numba æ”¯æ´ LLVM æ‰€ä»¥ä»–ç”šè‡³[æ¯”æ™®é€šçš„ C++ é‚„å¿«](https://stackoverflow.com/questions/70297011/why-is-numba-so-fast)ï¼Œæ‰€ä»¥æ–‡ç« ä½œè€…ç¨‹å¼ç¢¼ç¢°å·§å° LLVM å‹å–„æ™‚ï¼ˆå¤§å¤šæ•¸æ•™å­¸çš„ç¨‹å¼ç¢¼éƒ½æ˜¯ç¢°é‹æ°£çš„å“ªç®¡ä½ å‹ä¸å‹å–„ï¼‰é€Ÿåº¦å°±æœƒè®Šå¿«åä¹‹äº¦ç„¶ï¼Œä¹Ÿå°±æ˜¯èªªå–®ä¸€é …çš„å¯¦é©—ç„¡æ³•ä½œç‚ºä»£è¡¨åªèƒ½åƒè€ƒï¼Œå°¤å…¶æ˜¯ç•¶å‡½å¼è¶Šç°¡å–®ï¼ŒNumba ç•¶ç„¶è¶Šå¥½å„ªåŒ–ï¼Œè©²æ–‡ç« çš„ä»£è¡¨æ€§å°±è¶Šä½ï¼Œåªæ˜¯ç¶²è·¯æ–‡ç« å¯«é‚£éº¼è¤‡é›œèª°çœ‹å¾—å®Œï¼Œæ‰€ä»¥ä¹Ÿä¸æœƒæœ‰äººå¯«è¤‡é›œå‡½å¼ä¾†æ¸¬è©¦ã€‚

[^2]: ç”šè‡³é€£ geeksforgeeks çš„æ–‡ç«  [Numba vs. Cython: A Technical Comparison](https://www.geeksforgeeks.org/numba-vs-cython-a-technical-comparison/) éƒ½çŠ¯äº†ä¸€å€‹æœ€åŸºæœ¬çš„éŒ¯èª¤ï¼šæŠŠ Numba åˆæ¬¡ç·¨è­¯çš„æ™‚é–“ä¹Ÿç®—é€²å»ï¼Œè©²ä½œè€…ç”šè‡³éƒ½ä¸è¦ºå¾— Numba æ¯” Python é‚„ä¹…å¾ˆå¥‡æ€ªï¼Œé€™éº¼å¤§ä¸€å€‹çµ„ç¹”éƒ½éŒ¯äº†ï¼Œæˆ‘å€‘é‚„èƒ½æœŸæœ›ç¶²è·¯ä¸Šçš„æ–‡ç« å¤šæ­£ç¢ºå—ï¼Ÿå¦å¤–å¹«å¤§å®¶è·‘äº†ä»–çš„ç¨‹å¼ï¼Œåœ¨ colab ä¸Šå¯¦éš›é‹è¡Œæ™‚é–“é‹è¡ŒåŸ·è¡Œ 1000 æ¬¡å–å¹³å‡ï¼Œå…©è€…éƒ½æ˜¯ `1.58ms`ï¼Œå› ç‚ºä»–çš„ç¨‹å¼ç¢¼ç°¡å–®åˆ°å³ä½¿ Numba æ˜¯è‡ªå‹•å„ªåŒ–çš„ï¼Œä¹Ÿå¯ä»¥ç·¨è­¯å‡ºå’Œ Cython ä¸€æ¨£é€Ÿåº¦çš„æ©Ÿå™¨ç¢¼ï¼Œé™¤äº†è­‰å¯¦è¨»è…³äºŒçš„çŒœæƒ³ï¼Œä¹Ÿèªªæ˜è©²æ–‡ç« æ¯«ç„¡åƒè€ƒåƒ¹å€¼ã€‚

## åŸºç¤ä½¿ç”¨
èªªæ˜¯åŸºç¤ä½¿ç”¨ï¼Œä½†æ˜¯å·²ç¶“åŒ…å«å…«æˆçš„ä½¿ç”¨æƒ…å¢ƒã€‚

### ä¸€åˆ†é˜å­¸æœƒ Numba

æ¯”å®˜æ–¹çš„äº”åˆ†é˜æ•™å­¸åˆå¿«äº”å€ï¼Œå¤ ç‹ å§ã€‚é€™å€‹ç¯„ä¾‹æ¸¬è©¦å°é™£åˆ—é–‹æ ¹è™Ÿå¾ŒåŠ ç¸½çš„é€Ÿåº¦ï¼Œæ¯”è¼ƒæ¯å€‹å››ç¨®æ–¹æ³•çš„é‹ç®—æ™‚é–“ï¼Œåˆ†åˆ¥æ˜¯æœ‰æ²’æœ‰ä½¿ç”¨ Numba å’Œä½¿ç”¨é™£åˆ—æˆ–è€…è¿´åœˆã€‚

```py
import numpy as np
import time
from numba import jit, prange


@jit(nopython=True, fastmath=True, parallel=True, nogil=True)
def numba_loop(arr):
    # Numba + Loop
    bias = 2
    total = 0
    for x in prange(len(arr)):   # Numba likes loops
        total += np.sqrt(x)      # Numba likes numpy
    return bias + total          # Numba likes broadcasting


def python_loop(arr):
    # Python + Loop
    bias = 2
    total = 0.0
    for x in arr:
        total += np.sqrt(x)
    return bias + total


@jit(nopython=True, fastmath=True, parallel=True, nogil=True)
def numba_arr(arr):
    # Numba + Vector
    bias = 2
    return bias + np.sum(np.sqrt(arr))


def python_arr(arr):
    # Python + Vector
    bias = 2
    return bias + np.sum(np.sqrt(arr))


n_runs = 1000
n = 10000000
arr = np.arange(n)

# ç¬¬ä¸€æ¬¡é‹è¡Œçš„åˆå§‹åŒ–ï¼Œç¬¬äºŒæ¬¡ä»¥å¾Œæ‰æ˜¯å–®ç´”çš„åŸ·è¡Œæ™‚é–“
result_python_arr = python_arr(arr)
result_numba_arr = numba_arr(arr)
result_numba = numba_loop(arr)

start = time.time()
result_python = python_loop(arr)
end = time.time()
print(f"Pythonè¿´åœˆç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: {end - start} ç§’")

start = time.time()
result_python_arr = python_arr(arr)
end = time.time()
print(f"Pythoné™£åˆ—ç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: {end - start} ç§’")

start = time.time()
for _ in range(n_runs):
    result_numba = numba_loop(arr)
end = time.time()
print(f"Numbaè¿´åœˆç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: {(end - start)/n_runs} ç§’")

start = time.time()
for _ in range(n_runs):
    result_numba_arr = numba_arr(arr)
end = time.time()
print(f"Numbaé™£åˆ—ç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: {(end - start)/n_runs} ç§’")

print("Are the outputs equal?", np.isclose(result_numba, result_python))
print("Are the outputs equal?", np.isclose(result_numba_arr, result_python_arr))

# Pythonè¿´åœˆç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: 9.418870210647583 ç§’
# Pythoné™£åˆ—ç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: 0.021904706954956055 ç§’
# Numbaè¿´åœˆç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: 0.0013016948699951171 ç§’
# Numbaé™£åˆ—ç‰ˆæœ¬åŸ·è¡Œæ™‚é–“: 0.0024524447917938235 ç§’
# Are the outputs equal? True
# Are the outputs equal? True
```

é€™å€‹å¯¦é©—ä¸­æˆ‘å€‘å¯ä»¥çœ‹åˆ°ä½¿ç”¨ Numba å¾Œé€Ÿåº¦é‚„å¯ä»¥é¡å¤–æ¥è¿‘å…©å€ï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥ç™¼ç¾ä¸€å€‹æœ‰è¶£çš„äº‹å¯¦ï¼šã€Œè¿´åœˆç‰ˆæœ¬æ¯”é™£åˆ—ç‰ˆæœ¬æ›´å¿«ã€ï¼Œé€™å¼•å°æˆ‘å€‘åˆ°ç¬¬ä¸€å€‹é‡é» **Numba likes loops**ï¼Œä»–é‚„å–œæ­¡çš„å¦å¤–å…©å€‹æ˜¯ **Numpy** å’Œ **matrix broadcasting**ã€‚

å…©å…©æ¯”å°å‡½å¼å·®ç•°å¯ä»¥çœ‹åˆ°ä½¿ç”¨æ–¹å¼å¾ˆç°¡å–®ï¼Œåœ¨è¦å„ªåŒ–çš„å‡½å¼å‰åŠ ä¸Š `@jit` è£é£¾å™¨ï¼Œæ¥è‘—åœ¨è¦å¹³è¡ŒåŒ–è™•ç†çš„åœ°æ–¹é¡¯å¼çš„æ”¹ç‚º prange å°±å®Œæˆäº†ã€‚è£é£¾å™¨çš„é¸é …[æœ‰ä»¥ä¸‹å¹¾å€‹](https://numba.readthedocs.io/en/stable/user/jit.html#compilation-options)ï¼š

| åƒæ•¸      | èªªæ˜                                                      |
|----------|-----------------------------------------------------------|
| nopython | æ˜¯å¦åš´æ ¼å¿½ç•¥ Python C APIã€‚<br/>æ­¤åƒæ•¸æ˜¯æ•´ç¯‡æ–‡ç« ä¸­å½±éŸ¿é€Ÿåº¦æœ€å¤§çš„å› ç´ ï¼Œä½¿ç”¨ @njit ç­‰åƒ¹æ–¼å•Ÿç”¨æ­¤åƒæ•¸              |
| fastmath | æ˜¯å¦æ”¾å¯¬ IEEE 754 çš„ç²¾åº¦é™åˆ¶ä»¥ç²å¾—é¡å¤–æ€§èƒ½                     |
| cache    | æ˜¯å¦å°‡ç·¨è­¯çµæœå¯«å…¥å¿«å–ï¼Œé¿å…æ¯æ¬¡å‘¼å« Python ç¨‹å¼æ™‚éƒ½éœ€è¦ç·¨è­¯      |
| parallel | æ˜¯å¦ä½¿ç”¨å¹³è¡Œé‹ç®—                                             |
| nogil    | æ˜¯å¦é—œé–‰å…¨å±€é–                                              |

<br/>
<br/>

:::info å®‰å…¨æ€§æé†’

1. fastmath: æ¸¬è©¦æ™‚ä½¿ç”¨ï¼Œé›¢æ­£å¼ç”Ÿç”¢è¶Šè¿‘è¶Šè©²é—œé–‰ã€‚
2. ä¾ç­†è€…å€‹äººä½¿ç”¨ fastmath/nogil ä¸¦æ²’æœ‰å¿«å¤šå°‘ï¼Œç•¶ç„¶é€™æ˜¯ case-specificï¼Œåƒæ–‡æª”çš„ç¯„ä¾‹å°±æœ‰å·®ã€‚
3. numba æ¯æ¬¡ç·¨è­¯å¾Œå…¨åŸŸè®Šæ•¸æœƒè®Šç‚ºå¸¸æ•¸ï¼Œåœ¨ç¨‹å¼ä¸­ä¿®æ”¹è©²è®Šæ•¸ä¸æœƒè¢«å‡½å¼å¯Ÿè¦ºã€‚

:::


:::danger å®‰å…¨æ€§è­¦å‘Šï¼

**å°æ–¼æš«æ™‚ä¸æƒ³è™•ç†ç«¶çˆ­å±å®³çš„ç”¨æˆ¶ï¼Œè«‹å…ˆä¸è¦ä½¿ç”¨ `parallel` `nogil` æ–¹æ³•ã€‚**
1. parallel/nogil: å°å¿ƒ[ç«¶çˆ­å±å®³](https://zh.wikipedia.org/zh-tw/%E7%AB%B6%E7%88%AD%E5%8D%B1%E5%AE%B3) (race condition)ã€‚ç°¡å–®èªªæ˜ç«¶çˆ­å±å®³ï¼Œå°±æ˜¯å…©å€‹ç·šç¨‹ä¸€èµ·è™•ç†ä¸€å€‹é‹ç®— `x += 1`ï¼Œå…©å€‹ä¸€èµ·å–å€¼ï¼Œçµæœåˆ†åˆ¥å¯«å› x çš„å€¼éƒ½æ˜¯ `x+1` å°è‡´æœ€çµ‚çµæœæ˜¯ `x+1` è€Œä¸æ˜¯é æœŸçš„ `x+2`ã€‚
2. é›–ç„¶ä¸Šé¢çš„ç¯„ä¾‹é¡¯ç¤ºçµæœä¸€è‡´ï¼Œä½†é‚„æ˜¯ä¸€å®šè¦ **é¿å…ä»»ä½•å¯èƒ½çš„å¤šç·šç¨‹å•é¡Œï¼**

:::

<br/>

### é€²ä¸€æ­¥å„ªåŒ–æ•ˆèƒ½
åŸºç¤ä½¿ç”¨ç« ç¯€å·²ç¶“åŒ…å«å®˜æ–¹æ–‡æª”ä¸­æ‰€æœ‰æ•ˆèƒ½å„ªåŒ–æŠ€å·§ï¼Œåªæ˜¯æ²’æœ‰æ¯å€‹é¸é …[å„è‡ªå°æ¯”](https://numba.readthedocs.io/en/stable/user/performance-tips.html#intel-svml)ï¼Œé€™è£¡è£œå……å…¶ä»–æ•ˆèƒ½å„ªåŒ–æ–¹å¼ã€‚

1. å®‰è£ SVML (short vector math library), threading layers (å¹³è¡Œè¨ˆç®—, tbb/omp)ï¼Œå®‰è£å¾Œä¸éœ€è¨­å®šï¼ŒNumba æœƒè‡ªè¡Œèª¿ç”¨[^3]

[^3]: ç‚ºç”šéº¼æ•¢èªªæœ¬ç¯‡æ˜¯æœ€æ­£ç¢ºçš„æ•™å­¸ï¼Œå°æ–¼å…¶ä»–æ–‡ç« æˆ‘å°±å•ä¸€å¥è©±ï¼Œ **æ•ˆèƒ½æ¸¬è©¦æ™‚æœ‰è£ SVML å—ï¼Ÿ** é€™ç”šè‡³éƒ½ä¸ç”¨è¨­å®šå°±å¯ä»¥å¸¶ä¾†æ¥µå¤§å¹…åº¦çš„æ•ˆèƒ½æå‡ï¼Œä½†æ˜¯æˆ‘å¾ä¾†æ²’çœ‹éæœ‰äººæåˆ°éï¼Œå“ªæœ‰äººåš benchmark ä¸èªªæ˜ç’°å¢ƒçš„ï¼Œé‚£è‚¯å®šæ˜¯ä½œè€…è‡ªå·±ä¹Ÿä¸çŸ¥é“å°±é–‹å§‹è¦å¯«ä¸€é€šã€‚

```sh
# conda
conda install intel-cmplr-lib-rt
conda install tbb
conda install anaconda::intel-openmp

# pip
pip install intel-cmplr-lib-rt
pip install tbb
pip install intel-openmp

# Troubleshooting: æ²’æœ‰ç™¼ç¾ SVML çš„è§£æ±ºæ–¹å¼
# https://github.com/numba/numba/issues/4713#issuecomment-576015588
# numba -s   # æª¢æŸ¥æ˜¯å¦åµæ¸¬åˆ° SVML
# sudo pip3 install icc_rt; sudo ldconfig
```

2. ä½¿ç”¨ Numba åè€Œè®Šæ…¢
    - åˆ¥å¿˜äº†æ‰£æ‰é¦–æ¬¡åŸ·è¡Œéœ€è¦æ¶ˆè€—çš„ç·¨è­¯æ™‚é–“ã€‚
    - æª¢æŸ¥ I/O ç“¶é ¸ï¼Œä¸è¦æ”¾ä»»ä½•éœ€è¦ I/O çš„ç¨‹å¼ç¢¼åœ¨å‡½å¼ä¸­ã€‚
    - ç¸½è¨ˆç®—é‡å¤ªå°ã€‚
    - å®£å‘Šå¾Œå°±ä¸è¦ä¿®æ”¹çŸ©é™£ç¶­åº¦æˆ–å‹åˆ¥ã€‚
    - èªæ³•è¶Šç°¡å–®è¶Šå¥½ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•å„ç¨®åŒ…è£ï¼Œå› ç‚ºä½ ä¸çŸ¥é“ Numba æ˜¯å¦æ”¯æ´ã€‚
    - è¨˜æ†¶é«”å•é¡Œ [The wrong way to speed up your code with numba](https://pythonspeed.com/articles/slow-numba/)ã€‚

4. [threading layers è¨­å®šå¹³è¡Œè¨ˆç®—æ–¹å¼](https://numba.readthedocs.io/en/stable/user/threading-layer.html)
    - `default` provides no specific safety guarantee and is the default.
    - `safe` is both fork and thread safe, this requires the tbb package (Intel TBB libraries) to be installed.
    - `forksafe` provides a fork safe library.
    - `threadsafe` provides a thread safe library.
    <br/>

    ```py
    # è¨­å®šåªä½¿ç”¨å…©å€‹ç·šç¨‹åŸ·è¡Œï¼Œæ­¤æŒ‡ä»¤ç­‰æ•ˆæ–¼ NUMBA_NUM_THREADS=2
    # åœ¨æŸäº›æƒ…å½¢ä¸‹æ‡‰è©²è¨­å®šç‚ºè¼ƒä½çš„å€¼ï¼Œä»¥ä¾¿ numba å¯ä»¥èˆ‡æ›´é«˜å±¤ç´šçš„å¹³è¡Œæ€§ä¸€èµ·ä½¿ç”¨ã€‚
    # ä½†æ˜¯æ–‡æª”æ²’æœ‰èªªæ˜¯å“ªäº›æƒ…å½¢
    set_num_threads(2)
    sen: %s" % threading_layer())
    ```

5. ä½¿ç”¨ @guvectorize  
    æ•…æ„æ”¾æœ€å¾Œå› ç‚ºå¾ˆå¥‡æ€ªï¼Œè«‹è¦‹[ä¸‹æ–¹èªªæ˜](/docs/python/numba-tutorial-accelerate-python-computing#guvectorize)ã€‚

è®€åˆ°é€™è£¡ä½ å·²ç¶“å­¸æœƒåŸºç¤çš„ä½¿ç”¨æ–¹å¼ï¼Œèƒ½å¤ ç°¡å–®çš„ä½¿ç”¨ Numbaã€‚å¦‚æœæœ‰ç«¶çˆ­å±å®³çš„çŸ¥è­˜å†é–‹å•Ÿè‡ªå‹•å¹³è¡ŒåŒ–åŠŸèƒ½ï¼Œå¦å‰‡è«‹å‹™å¿…é—œé–‰ä»¥å…è·‘å¾ˆå¿«ä½†å…¨éŒ¯ã€‚

### å¦‚ä½•é™¤éŒ¯
Numba å®˜æ–¹æ–‡æª”æœ‰å¦‚ä½•é™¤éŒ¯çš„è©³ç´°æ•™å­¸ï¼Œä½¿ç”¨ `@jit(debug=True)`ï¼Œè©³æƒ…è«‹è¦‹ [Troubleshooting and tips](https://numba.readthedocs.io/en/stable/user/troubleshoot.html)ã€‚

å¦å¤–ä¸€å€‹æ˜¯ç­†è€…çš„åœŸç ²æ–¹æ³•ï¼Œç•¶å¹´åœ¨å¯« Numba åœ¨å‡ºç¾éŒ¯èª¤æ™‚ Numba çš„å ±éŒ¯è³‡è¨Šä¸æ˜ç¢ºï¼Œé‚£æ™‚çš„åœŸç ²æ–¹æ³•æ˜¯ã€Œæ‰¾åˆ°éŒ¯èª¤è¡Œæ•¸çš„æ–¹å¼æ˜¯äºŒåˆ†æ³•ç›´æ¥åˆªç¨‹å¼ç¢¼åˆ° Numba ä¸å ±éŒ¯ã€

éŒ¯èª¤é€šå¸¸ä¾†è‡ªæ–¼ä½¿ç”¨ Numba ä¸æ”¯æ´çš„å‡½å¼ï¼Œé™¤éŒ¯è«‹å…ˆçœ‹å‡½å¼æ˜¯å¦æ”¯æ´ä»¥å…ç•¶å†¤å¤§é ­ï¼Œå†ä¾†å°±æ˜¯æª¢æŸ¥è®Šæ•¸å‹åˆ¥éŒ¯èª¤ï¼Œä¾‹å¦‚èª¤ç”¨ä¸æ”¯æ´ç›¸åŠ çš„ä¸åŒçš„è®Šæ•¸å‹åˆ¥ã€‚

- [Supported Python features](https://numba.readthedocs.io/en/stable/reference/pysupported.html)
- [Supported NumPy features](https://numba.readthedocs.io/en/stable/reference/numpysupported.html)


### å°çµ
1. Numba likes loops åœ¨å¿ƒè£¡é»˜å¿µåæ¬¡
2. Numba likes NumPy functions
3. Numba likes NumPy broadcasting
4. ä¸è¦åœ¨å‡½å¼å…§ä¿®æ”¹æ•¸æ“šçµæ§‹ 
5. ä¿æŒé †åºè¨˜æ†¶é«”è®€å–
6. å‡½å¼ä¸­ä¸è¦åŒ…å« I/O æ“ä½œ
7. æ‰€æœ‰å„ªåŒ–æ–¹å¼éƒ½æ˜¯ case-specificï¼Œä¸èƒ½èªª parallel å„ªåŒ–å¹…åº¦ä¸€å®šå¾ˆå°æˆ–è€… njit ä¸€å®šå¾ˆå¿«ï¼Œä¸€åˆ‡å–æ±ºæ–¼è¢«ç·¨è­¯çš„ç¨‹å¼ç¢¼å¦‚ä½•è¨­è¨ˆ
8. ***é‚„æ˜¯ Numba likes loops***

åˆ°é€™è£¡å°±çµæŸåŸºæœ¬ä½¿ç”¨äº†ï¼Œå»ºè­°å…ˆä¸è¦çœ‹é€²éšä½¿ç”¨ï¼Œè€Œæ˜¯è·³åˆ° [See Also](/docs/python/numba-tutorial-accelerate-python-computing#see-also) çœ‹å»¶ä¼¸é–±è®€ã€‚

---

## è‡ªå‹•å¹³è¡ŒåŒ–èˆ‡ç«¶çˆ­å±å®³
æœ¬ç« ç¯€æ•´ç†è‡ªå®˜æ–¹æ–‡æª” [Automatic parallelization with @jit](https://numba.readthedocs.io/en/stable/user/parallel.html#)ï¼Œé–±è®€æœ¬ç« ç¯€å‰è«‹å…ˆç¢ºä¿ä½ å°ç«¶çˆ­å±å®³æœ‰ä¸€å®šç¨‹åº¦çš„ç†è§£ï¼Œå¦å‰‡è«‹è·³éæœ¬ç« ç¯€ï¼Œä¸¦ä¸”**ä¸è¦é–‹å•Ÿ parallel å’Œ nogil åŠŸèƒ½**ã€‚

### è‡ªå‹•å¹³è¡ŒåŒ–

> è¨­å®š Numba è‡ªå‹•å¹³è¡ŒåŒ–çš„å®˜æ–¹æ–‡æª”ï¼Œç”±æ–¼å¾ˆç²¾ç·´ï¼ŒçŸ¥è­˜ä¹Ÿå¾ˆé‡è¦ï¼Œæ‰€ä»¥ç¿»è­¯å®Œè²¼åœ¨é€™è£¡ã€‚  
> ç°¡å–®ä¾†èªªï¼Œç¶²è·¯ä¸Šæ‰‹åˆ»å¹³è¡ŒåŒ–çš„äººé€£æ–‡æª”éƒ½æ²’çœ‹å°±é–‹å§‹äº‚å¯«æ–‡ç« äº†ã€‚Numba æ”¯æ´è‡ªå‹•å¹³è¡ŒåŒ–ï¼Œä¸¦ä¸”å¿«å–å„ªåŒ–æ›´å¥½ï¼Œæ‰‹åˆ»æ²’æœ‰ä»»ä½•å¥½è™•ã€‚

åœ¨ `jit()` å‡½å¼ä¸­è¨­ç½® `parallel` é¸é …ï¼Œå¯ä»¥å•Ÿç”¨ Numba çš„è½‰æ›éç¨‹ï¼Œå˜—è©¦è‡ªå‹•å¹³è¡ŒåŒ–å‡½å¼ï¼ˆæˆ–éƒ¨åˆ†å‡½å¼ï¼‰ä»¥åŸ·è¡Œå…¶ä»–å„ªåŒ–ã€‚ç›®å‰æ­¤åŠŸèƒ½åƒ…é©ç”¨æ–¼CPUã€‚

ä¸€äº›åœ¨ç”¨æˆ¶å®šç¾©çš„å‡½å¼ä¸­åŸ·è¡Œçš„æ“ä½œï¼ˆä¾‹å¦‚å°é™£åˆ—åŠ ä¸Šç´”é‡ï¼‰å·²çŸ¥å…·æœ‰å¹³è¡Œèªç¾©ã€‚ç”¨æˆ¶çš„ç¨‹å¼ç¢¼å¯èƒ½åŒ…å«å¾ˆå¤šé€™ç¨®æ“ä½œï¼Œé›–ç„¶æ¯å€‹æ“ä½œéƒ½å¯ä»¥å–®ç¨å¹³è¡ŒåŒ–ï¼Œä½†é€™ç¨®æ–¹æ³•é€šå¸¸æœƒå› ç‚ºå¿«å–è¡Œç‚ºä¸ä½³è€Œå°è‡´æ€§èƒ½ä¸‹é™ã€‚ç›¸ååœ°ï¼Œé€šéè‡ªå‹•å¹³è¡ŒåŒ–ï¼ŒNumba æœƒå˜—è©¦è­˜åˆ¥ç”¨æˆ¶ç¨‹å¼ç¢¼ä¸­çš„é€™é¡æ“ä½œä¸¦å°‡ç›¸é„°çš„æ“ä½œåˆä½µåˆ°ä¸€èµ·ï¼Œå½¢æˆä¸€å€‹æˆ–å¤šå€‹è‡ªå‹•å¹³è¡ŒåŸ·è¡Œçš„ kernelsã€‚é€™å€‹éç¨‹æ˜¯å®Œå…¨è‡ªå‹•çš„ï¼Œç„¡éœ€ä¿®æ”¹ç”¨æˆ¶ç¨‹å¼ç¢¼ï¼Œé€™èˆ‡ Numba çš„ `vectorize()` æˆ– `guvectorize()` æ©Ÿåˆ¶å½¢æˆå°æ¯”ï¼Œå¾Œè€…éœ€è¦æ‰‹å‹•å‰µå»ºä¸¦è¡Œ kernelsã€‚


- [**æ”¯æ´çš„é‹ç®—ç¬¦**](https://apachecn.github.io/numba-doc-zh/#/docs/21?id=_1101%e3%80%82%e6%94%af%e6%8c%81%e7%9a%84%e6%93%8d%e4%bd%9c)  
æ­¤è™•åˆ—å‡ºæ‰€æœ‰å¸¶æœ‰å¹³è¡ŒåŒ–èªç¾©çš„é‹ç®—ç¬¦ï¼ŒNumba æœƒè©¦åœ–å¹³è¡ŒåŒ–é€™äº›é‹ç®—ã€‚

:::note Reduction ç¿»è­¯

ä¸­æ–‡æ–‡æª”ç¿»è­¯éŒ¯èª¤ï¼Œé€™è£¡çš„ reduction åˆ†ç‚ºå…©ç¨®æƒ…æ³ï¼Œä¸€æ˜¯å¹³è¡ŒåŒ–è™•ç†çš„è¡“èª parallel reduction [^reduction1] [^reduction2]ï¼ŒæŒ‡çš„æ˜¯ã€Œå°‡å„å€‹åŸ·è¡Œç·’çš„è®Šæ•¸å¯«å›ä¸»åŸ·è¡Œç·’ã€ï¼ŒäºŒæ˜¯æ¸›å°‘ï¼Œä»£è¡¨è©²å‡½å¼é™ä½è¼¸å…¥ç¶­åº¦ï¼Œå…¨éƒ¨ç¿»è­¯æˆæ¸›å°‘é¡¯ç„¶èªæ„éŒ¯èª¤ã€‚

[^reduction1]: [å¹³è¡Œç¨‹å¼è¨­è¨ˆçš„ç°¡å–®ç¯„ä¾‹](https://datasciocean.tech/others/parallel-programming-example/)
[^reduction2]: [Avoid Race Condition in Numba](https://stackoverflow.com/questions/61372937/avoid-race-condition-in-numba)
:::

- **é¡¯å¼çš„æ¨™æ˜å¹³è¡ŒåŒ–çš„è¿´åœˆ**  
ä½¿ç”¨ `prange` å–ä»£ `range` é¡¯å¼çš„æ¨™æ˜å¹³è¡ŒåŒ–çš„è¿´åœˆï¼Œå°æ–¼å¤šå€‹å·¢ç‹€çš„ `prange` åªæœƒå¹³è¡ŒåŒ–æœ€å¤–å±¤çš„è¿´åœˆï¼Œåœ¨è£é£¾å™¨ä¸­è¨­å®š `parallel=False` ä¹Ÿæœƒå°è‡´ `prange` å›é€€ç‚ºä¸€èˆ¬çš„ `range`ã€‚

### ç«¶çˆ­å±å®³
é€™è£¡å±•ç¤ºç«¶çˆ­å±å®³çš„ç¯„ä¾‹å’Œè§£æ±ºæ–¹å¼ï¼Œé¡¯ç¤ºå‡ºç«¶çˆ­å±å®³çš„å­˜åœ¨ï¼Œè«‹ä¸è¦éŒ¯èª¤çš„æ¨æ–·ç‚º scalar é‹ç®—å¯ä»¥é¿å…è€Œ vector é‹ç®—ä¸è¡Œï¼Œ**ä»»ä½•æ™‚å€™æˆ‘å€‘éƒ½æ‡‰è©²é¿å…ç«¶çˆ­å±å®³çš„å¯èƒ½**ã€‚é‚£æˆ‘å€‘å°±ä¸èƒ½å¯« for è¿´åœˆäº†å—ï¼Ÿå…¶å¯¦æœ‰å…¶ä»–æ–¹æ³•ï¼Œä¾‹å¦‚é€™ä¸‹é¢çš„è§£æ±ºæ–¹å¼å’Œæ­£ç¢ºä½¿ç”¨ç¯„ä¾‹ã€‚

<!-- <details>
<summary>ç«¶çˆ­å±å®³ç¯„ä¾‹</summary> -->

<Tabs>
  <TabItem value="1" label="ç™¼ç”Ÿç«¶çˆ­å±å®³çš„ç¯„ä¾‹">

```py
from numba import njit, prange
import numpy as np


@njit(parallel=True)
def prange_wrong_result_numba(x):
    n = x.shape[0]
    y = np.zeros(4)
    for i in prange(n):
        # ä¸€èˆ¬çš„çŸ©é™£ç›¸åŠ ï¼Œæœƒé€ æˆç«¶çˆ­å±å®³
        y[:] += x[i]
    return y


@njit(parallel=True)
def prange_wrong_result_mod_numba(x):
    n = x.shape[0]
    y = np.zeros(4)
    for i in prange(n):
        # å„ªåŒ–å¾Œçš„çŸ©é™£ç›¸åŠ ï¼Œå˜—è©¦åˆ©ç”¨ä¸åŒçš„ i å–é¤˜æ•¸é¿å…ç«¶çˆ­å±å®³ï¼Œä»èˆŠå¤±æ•—
        y[i % 4] += x[i]
    return y


# æ²’æœ‰åŠ ä¸Šè£é£¾å™¨çš„ç‰ˆæœ¬
def prange_wrong_result_python(x):
    n = x.shape[0]
    y = np.zeros(4)
    for i in range(n):
        y[:] += x[i]
    return y


# æ²’æœ‰åŠ ä¸Šè£é£¾å™¨çš„ç‰ˆæœ¬
def prange_wrong_result_mod_python(x):
    n = x.shape[0]
    y = np.zeros(4)
    for i in range(n):
        y[i % 4] += x[i]
    return y


# æé†’ï¼šä½¿ç”¨æµ®é»æ•¸æ¸¬è©¦æ™‚å› æµ®é»æ•¸ç‰¹æ€§æ¯æ¬¡è¨ˆç®—çµæœéƒ½æœƒæœ‰èª¤å·®ï¼Œæ‰€ä»¥æ¯”è¼ƒæ™‚æ‡‰è©²ä½¿ç”¨æ•´æ•¸æ¸¬è©¦
x = np.random.randint(-10, 100, size=1000000)

result_numba = prange_wrong_result_numba(x)
result_python = prange_wrong_result_python(x)
print("Are the outputs equal?", np.array_equal(result_numba, result_python))

result_numba_mod = prange_wrong_result_mod_numba(x)
result_python_mod = prange_wrong_result_mod_python(x)
print("Are the outputs equal?", np.array_equal(result_numba_mod, result_python_mod))

# è¼¸å‡º

# Are the outputs equal? False
# Are the outputs equal? False
```
</TabItem>

  <TabItem value="2" label="è§£æ±ºæ–¹å¼">

```py
from numba import njit, prange
import numpy as np


@njit(parallel=True)
def prange_ok_result_whole_arr(x):
    n = x.shape[0]
    y = np.zeros(4)
    for i in prange(n):
        # "whereas performing a whole array reduction is fine" ç¯€éŒ„è‡ªå®˜æ–¹æ–‡æª”
        y += x[i]
    return y


@njit(parallel=True)
def prange_ok_result_outer_slice(x):
    n = x.shape[0]
    y = np.zeros(4)
    z = y[:]
    for i in prange(n):
        # "as is creating a slice reference outside of the parallel reduction loop" ç¯€éŒ„è‡ªå®˜æ–¹æ–‡æª”
        z += x[i]
    return y


# æ²’æœ‰åŠ ä¸Šè£é£¾å™¨çš„ç‰ˆæœ¬
def prange_ok_result_whole_arr_python(x):
    n = x.shape[0]
    y = np.zeros(4)
    for i in prange(n):
        y += x[i]
    return y


# æ²’æœ‰åŠ ä¸Šè£é£¾å™¨çš„ç‰ˆæœ¬
def prange_ok_result_outer_slice_python(x):
    n = x.shape[0]
    y = np.zeros(4)
    z = y[:]
    for i in prange(n):
        z += x[i]
    return y


# æé†’ï¼šä½¿ç”¨æµ®é»æ•¸æ¸¬è©¦æ™‚å› æµ®é»æ•¸ç‰¹æ€§æ¯æ¬¡è¨ˆç®—çµæœéƒ½æœƒæœ‰èª¤å·®ï¼Œæ‰€ä»¥æ¯”è¼ƒæ™‚æ‡‰è©²ä½¿ç”¨æ•´æ•¸æ¸¬è©¦
x = np.random.randint(-10, 100, size=(1000000, 4))

result_numba_whole_arr = prange_ok_result_whole_arr(x)
result_python_whole_arr = prange_ok_result_whole_arr_python(x)
print("Are the outputs equal?", np.array_equal(result_numba_whole_arr, result_python_whole_arr))

result_numba_outer_slice = prange_ok_result_outer_slice(x)
result_python_outer_slice = prange_ok_result_outer_slice_python(x)
print("Are the outputs equal?", np.array_equal(result_numba_outer_slice, result_python_outer_slice))

# è¼¸å‡º

# Are the outputs equal? True
# Are the outputs equal? True
```

</TabItem>


  <TabItem value="3" label="æ­£ç¢ºä½¿ç”¨ç¯„ä¾‹">

```py
from numba import njit, prange
import numpy as np

@njit(parallel=True)
def prange_test(A):
    s = 0
    # Without "parallel=True" in the jit-decorator
    # the prange statement is equivalent to range
    for i in prange(A.shape[0]):
        s += A[i]
    return s

@njit(parallel=True)
def two_d_array_reduction_prod(n):
    shp = (13, 17)
    result1 = 2 * np.ones(shp, np.int_)
    tmp = 2 * np.ones_like(result1)

    for i in prange(n):
        result1 *= tmp

    return result1


n = 100000
A = np.random.randint(-5, 10, size=n)
result_numba_test = prange_test(A)
result_python_test = sum(A)
print("Are the outputs equal?", np.array_equal(result_numba_test, result_python_test))

result_numba_prod = two_d_array_reduction_prod(n)
result_python_prod = np.power(2, n) * np.ones((13, 17), dtype=np.int_)
print("Are the outputs equal?", np.array_equal(result_numba_prod, result_python_prod))

# è¼¸å‡º

# Are the outputs equal? True
# Are the outputs equal? True
```

</TabItem>


</Tabs>

<!-- </details> -->

:::info è¿´åœˆå‡ºå£

`prange` ä¸æ”¯æ´å¤šå€‹å‡ºå£çš„è¿´åœˆï¼Œä¾‹å¦‚è¿´åœˆä¸­é–“åŒ…å« `assert`ã€‚

:::

:::warning è¿´åœˆè®Šæ•¸éš±æ€§è½‰å‹

é—œé–‰å¹³è¡ŒåŒ–è™•ç†æ™‚è¿´åœˆè®Šæ•¸ (induction variable) æ²’æœ‰å•é¡Œï¼Œå’Œ Python é è¨­ä¸€æ¨£ä½¿ç”¨æœ‰è™Ÿæ•´æ•¸ã€‚ç„¶è€Œå¦‚æœé–‹å•Ÿå¹³è¡ŒåŒ–ä¸”ç¯„åœå¯è¢«è­˜åˆ¥ç‚ºåš´æ ¼æ­£æ•¸ï¼Œå‰‡æœƒè¢«è‡ªå‹•è½‰å‹ç‚º `uint64`ï¼Œè€Œ `uint64` å’Œå…¶ä»–è®Šæ•¸è¨ˆç®—æ™‚**æœ‰æ©Ÿæœƒä¸å°å¿ƒçš„è¿”å›ä¸€å€‹æµ®é»æ•¸**ã€‚

:::



### å¹³è¡ŒåŒ–çš„å„ªåŒ–æŠ€å·§

ä»‹ç´¹å¦‚ä½•æ’°å¯«è¿´åœˆæ‰å¯ä½¿ Numba åŠ é€Ÿæœ€å¤§åŒ–çš„æŠ€å·§ã€‚

1. **è¿´åœˆèåˆ (Loop Fusion)ï¼š** å°‡ç›¸åŒè¿´åœˆé‚Šç•Œçš„è¿´åœˆåˆä½µæˆä¸€å€‹å¤§è¿´åœˆï¼Œæé«˜è³‡æ–™å±€éƒ¨æ€§é€²è€Œæå‡æ•ˆèƒ½ã€‚
2. **è¿´åœˆåºåˆ—åŒ– (Loop Serialization)ï¼š** Numba ä¸æ”¯æ´å·¢ç‹€å¹³è¡ŒåŒ–ï¼Œç•¶å¤šå€‹ `prange` è¿´åœˆåµŒå¥—æ™‚åªæœ‰æœ€å¤–å±¤çš„ `prange` è¿´åœˆæœƒè¢«å¹³è¡ŒåŒ–ï¼Œå…§å±¤çš„ `prange` è¿´åœˆæœƒè¢«è¦–ç‚ºæ™®é€šçš„ `range` åŸ·è¡Œã€‚
3. **æå‡ºä¸è®Šçš„ç¨‹å¼ç¢¼ (Loop Invariant Code Motion)ï¼š** å°‡ä¸å½±éŸ¿è¿´åœˆçµæœçš„èªå¥ç§»åˆ°è¿´åœˆå¤–ã€‚
4. **åˆ†é…å¤–æ (Allocation Hoisting)**ï¼šç¯„ä¾‹æ˜¯æ‹†åˆ† `np.zeros` æˆ `np.empty` å’Œ `temp[:] = 0` é¿å…é‡è¤‡åˆå§‹åŒ–åˆ†é…ã€‚

é€²ä¸€æ­¥å„ªåŒ–ï¼šä½¿ç”¨è¨ºæ–·åŠŸèƒ½ï¼Œè«‹è¦‹ [Diagnostics your parallel optimization](https://numba.readthedocs.io/en/stable/user/parallel.html#diagnostics)ã€‚

## é€²éšä½¿ç”¨

```sh
# é€™æ˜¯ç”¨ä¾†é˜»æ­¢ä½ ç¹¼çºŒè®€çš„ placeholderï¼
 _   _                       _             
| \ | |  _   _   _ __ ___   | |__     __ _ 
|  \| | | | | | | '_ ` _ \  | '_ \   / _` |
| |\  | | |_| | | | | | | | | |_) | | (_| |
|_| \_|  \__,_| |_| |_| |_| |_.__/   \__,_|

```
é™¤éä½ æ˜¯é€²éšç”¨æˆ¶ï¼Œå¦å‰‡ **ä½ ä¸æ‡‰è©²çœ‹é€²éšä½¿ç”¨ç« ç¯€ï¼** çœ‹äº†åè€Œæ¨¡ç³Šç„¦é»ï¼Œä½ æ‡‰è©²æŠŠæ¡å¥½å¦‚ä½•åŸºç¤ä½¿ç”¨ï¼ŒåŸºç¤ä½¿ç”¨å·²ç¶“åŒ…å«äº†å…«æˆä»¥ä¸Šçš„ä½¿ç”¨æƒ…æ™¯ã€‚

é€²éšä½¿ç”¨è£¡é¢å°±åªæœ‰ [ä½¿ç”¨å­—å…¸å‚³éåƒæ•¸](/docs/python/numba-tutorial-accelerate-python-computing#numbatypeddict) ä½ å¯ä»¥å…ˆå·çœ‹ã€‚

### ä½¿ç”¨ CUDA åŠ é€Ÿé‹ç®—
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/cuda/overview.html)

> é€™å°±åŸºç¤ä½¿ç”¨ä½¿ç”¨æƒ…å¢ƒä¹‹å¤–çš„å…¶ä¸­ä¸€æˆä½¿ç”¨æƒ…å¢ƒã€‚

å„ªåŒ– CUDA ä¸åƒå„ªåŒ– CPU åŠ ä¸Šè£é£¾å™¨é‚£éº¼ç°¡å–®ï¼Œè€Œæ˜¯è¦é‡å° CUDA ç‰¹åˆ¥å¯«å‡½å¼ï¼Œå°è‡´ç¨‹å¼åªèƒ½åœ¨ GPU ä¸Šè·‘ï¼Œæ‰€ä»¥ç­†è€…ç›®å‰é‚„æ²’å¯«éï¼Œä¸éåŸºæœ¬æ³¨æ„äº‹é …ä¸€æ¨£æ˜¯æ³¨æ„ IOã€å·¥ä½œé‡å¤ªå°çš„ä¸é©åˆ CUDAã€‚é‚£æ¯”è¼ƒä»€éº¼å‡½å¼é©åˆ CPU è€Œä¸æ˜¯ CUDA å‘¢ï¼Ÿ

1. **é †åºè™•ç†è€Œä¸æ˜¯å¹³è¡Œè™•ç†**ï¼Œå½±åƒè™•ç†ä»¥å¤–çš„æ¼”ç®—æ³•å¤§æ¦‚éƒ½æ˜¯é€™é¡
2. è¨˜æ†¶é«”è¶…éé¡¯å¡è¨˜æ†¶é«”ä¸Šé™ï¼ˆè¨»ï¼šä¸æ‡‰è©²å¯«å‡ºé€™ç¨®ç¨‹å¼ï¼ŒNumba likes loopsï¼‰
3. å¤§é‡åˆ†æ”¯è™•ç† (if-else)ï¼ˆè¨»ï¼šä¸æ‡‰è©²å¯«å‡ºé€™ç¨®ç¨‹å¼ï¼Œå°¤å…¶åœ¨ Numba ä¸­ï¼‰
4. é¡¯å¡é›™ç²¾åº¦æµ®é»é‹ç®—æ•ˆèƒ½å·®ï¼Œæ·±åº¦å­¸ç¿’å’ŒéŠæˆ²éƒ½åƒå–®ç²¾åº¦ï¼Œä½†æ˜¯ç§‘å­¸è¨ˆç®—éœ€è¦é›™ç²¾åº¦ï¼Œæˆ‘å€‘åˆåªèƒ½è²·åˆ°éŠæˆ²å¡
5. ä¸€äº› library åªæ”¯æ´ CPUï¼Œé€™è¦è©¦äº†æ‰çŸ¥é“

å¦‚æœä½ éœ€è¦ä½¿ç”¨ CUDAï¼Œé€™è£¡ä¹Ÿæœ‰å¥½ç”¨çš„æŒ‡å—é€£çµï¼š

- [28000x speedup with numba.CUDA](https://curiouscoding.nl/posts/numba-cuda-speedup/)ï¼šä½¿ç”¨ CUDA åŠ é€Ÿä¸¦ä¸”æœ‰å®Œæ•´çš„å°æ¯”ã€‚  
- [ç”¨ numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸Š)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8A-ede7b381f6c7)
- [ç”¨ numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸‹)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8B-770c11bffd37)


### ä½¿ç”¨å­—å…¸å‚³éåƒæ•¸
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/reference/pysupported.html#typed-dict)

ä½œç‚ºæ•¸å€¼æ¨¡æ“¬æˆ‘å€‘ä¸€å®šæœƒé‡åˆ°åƒæ•¸é‡è¶…å¤šçš„å•é¡Œï¼Œnumba å…¶å¯¦æ”¯æ´[ç”¨å­—å…¸å‚³éåƒæ•¸](https://stackoverflow.com/questions/55078628/using-dictionaries-with-numba-njit-function)ã€‚


### Signature
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/reference/types.html)

é¡¯å¼çš„å‘Šè¨´ numba å‹åˆ¥ï¼Œç”¨æ–¼è¼¸å…¥ç¶­åº¦å¯è®Šï¼Œæˆ–è€…ä½¿ç”¨ AoT ç·¨è­¯ç­‰ï¼Œæœ‰æ¨™ç¤ºå°ä¹Ÿä¸æœƒæ¯”è¼ƒå¿«ã€‚[å¯ç”¨çš„ signature åˆ—è¡¨](https://numba.readthedocs.io/en/stable/reference/types.html#numbers)ã€‚

- [è¼¸å…¥ç¶­åº¦å¯è®Š](https://stackoverflow.com/questions/66205186/python-signature-with-numba)ï¼ŒåŒ…å« guvectorize å’Œ [jitclass](https://numba.readthedocs.io/en/stable/user/jitclass.html)
- [AoT ç·¨è­¯](https://numba.readthedocs.io/en/stable/user/pycc.html#limitations): é™åˆ¶éœ€è¦é¡¯å¼æŒ‡å®š signature


<details>
<summary>ç°¡å–®çš„ Numba signature ç¯„ä¾‹å’Œæ•ˆèƒ½æ¸¬è©¦</summary>

é€™è£¡çš„çµæœå¾ˆå¥‡æ€ªï¼Œæˆ‘é æœŸæ‡‰è©²æ˜¯ç›¸å·®ä¸å¤šï¼Œçµæœåè€Œé¡¯å¼æ¯”è¼ƒæ…¢ã€‚æ¸¬è©¦åœ¨ apple M1 ä¸Šé‹è¡Œï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯ apple silicon åœ¨æé¬¼ï¼Œx86 çš„ç”¨æˆ¶å¯ä»¥åœ¨è‡ªå·±é›»è…¦ä¸ŠåŸ·è¡Œçœ‹çœ‹çµæœå¦‚ä½•ã€‚

```py
import numpy as np
import numba as nb
import time


# ä½¿ç”¨é¡¯å¼ signature
@nb.jit("float64[:](float64[:], float64[:])", nopython=True)
def add_and_sqrt(x, y):
    result = np.empty_like(x)
    for i in range(len(x)):
        result[i] = np.sqrt(x[i] + y[i])
    return result


# ä¸ä½¿ç”¨é¡¯å¼ signature
@nb.jit(nopython=True)
def add_and_sqrt_no_sig(x, y):
    result = np.empty_like(x)
    for i in range(len(x)):
        result[i] = np.sqrt(x[i] + y[i])
    return result


# æ¸¬è©¦å‡½æ•¸
def test_function(func, x, y, num_runs=1000):
    start_time = time.time()
    for _ in range(num_runs):
        _ = func(x, y)
    end_time = time.time()
    return (end_time - start_time) / num_runs


if __name__ == "__main__":
    x = np.random.random(100000)
    y = np.random.random(100000)

    _ = add_and_sqrt(x, y)
    _ = add_and_sqrt_no_sig(x, y)

    time_with_sig = test_function(add_and_sqrt, x, y)
    time_without_sig = test_function(add_and_sqrt_no_sig, x, y)

    print(f"ä½¿ç”¨é¡¯å¼ signature çš„å¹³å‡åŸ·è¡Œæ™‚é–“: {time_with_sig:.6f} ç§’")
    print(f"ä¸ä½¿ç”¨é¡¯å¼ signature çš„å¹³å‡åŸ·è¡Œæ™‚é–“: {time_without_sig:.6f} ç§’")
    print(f"æ€§èƒ½å·®ç•°: {abs(time_with_sig - time_without_sig) / time_without_sig * 100:.2f}%")

    result_with_sig = add_and_sqrt(x, y)
    result_without_sig = add_and_sqrt_no_sig(x, y)
    print(f"çµæœæ˜¯å¦ç›¸åŒ: {np.allclose(result_with_sig, result_without_sig)}")

# ä½¿ç”¨é¡¯å¼ signature çš„å¹³å‡åŸ·è¡Œæ™‚é–“: 0.000104 ç§’
# ä¸ä½¿ç”¨é¡¯å¼ signature çš„å¹³å‡åŸ·è¡Œæ™‚é–“: 0.000052 ç§’
# æ€§èƒ½å·®ç•°: 99.58%
# çµæœæ˜¯å¦ç›¸åŒ: True
```

</details>

<details>
<summary>è¤‡é›œçš„ Numba signature ç¯„ä¾‹</summary>

ä¿®æ”¹è‡ª https://stackoverflow.com/questions/30363253/multiple-output-and-numba-signatures 

```py
import numpy as np
import numba as nb

# è¼¸å…¥å…©å€‹ä¸€ç¶­æµ®é»æ•¸é™£åˆ—ï¼Œè¿”å›å…©å€‹ä¸€ç¶­æµ®é»æ•¸é™£åˆ—
@nb.jit(nb.types.UniTuple(nb.float64[:], 2)(nb.float64[:], nb.float64[:]), nopython=True)
def homogeneous_output(a, b):
    return np.sqrt(a), np.sqrt(b)

# å­—ä¸²è¡¨ç¤º
@nb.jit('UniTuple(float64[:], 2)(float64[:], float64[:])', nopython=True)
def homogeneous_output_str(a, b):
    return np.sqrt(a), np.sqrt(b)

# ç•°è³ªé¡å‹è¿”å›å€¼
@nb.jit(nb.types.Tuple((nb.float64[:], nb.float64[:,:]))(nb.float64[:], nb.int64[:,:]), nopython=True)
def heterogeneous_output(a, b):
    return np.sqrt(a), b.astype(np.float64)

# ä½¿ç”¨å­—ä¸²è¡¨ç¤º
@nb.jit('Tuple((float64[:], float64[:,:]))(float64[:], int64[:,:])', nopython=True)
def heterogeneous_output_str(a, b):
    return np.sqrt(a), b.astype(np.float64)

if __name__ == "__main__":
    a = np.array([1., 4., 9., 16.], dtype=np.float64)
    b = np.array([25., 36., 49., 64.], dtype=np.float64)
    c = np.array([[1, 2], [3, 4]], dtype=np.int64)

    # æ¸¬è©¦åŒè³ªé¡å‹è¼¸å‡º
    result1, result2 = homogeneous_output(a, b)
    print("åŒè³ªé¡å‹è¼¸å‡º (ä½¿ç”¨ nb.types):")
    print("çµæœ 1:", result1)
    print("çµæœ 2:", result2)

    result1, result2 = homogeneous_output_str(a, b)
    print("\nåŒè³ªé¡å‹è¼¸å‡º (ä½¿ç”¨å­—ç¬¦ä¸²):")
    print("çµæœ 1:", result1)
    print("çµæœ 2:", result2)

    # æ¸¬è©¦ç•°è³ªé¡å‹è¼¸å‡º
    result3, result4 = heterogeneous_output(a, c)
    print("\nç•°è³ªé¡å‹è¼¸å‡º (ä½¿ç”¨ nb.types):")
    print("çµæœ 3:", result3)
    print("çµæœ 4:\n", result4)

    result3, result4 = heterogeneous_output_str(a, c)
    print("\nç•°è³ªé¡å‹è¼¸å‡º (ä½¿ç”¨å­—ç¬¦ä¸²):")
    print("çµæœ 3:", result3)
    print("çµæœ 4:\n", result4)
```

</details>


### å…¶ä»–è£é£¾å™¨
å¸¸è¦‹è£é£¾å™¨æœ‰

- vectorize
- guvectorize
- jitclass
- stencil

#### vectorize
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-vectorize-decorator)

å…è¨±æŠŠ scalar è¼¸å…¥çš„å‡½å¼ç•¶ä½œå‘é‡ [Numpy ufunc](http://docs.scipy.org/doc/numpy/reference/ufuncs.html) ä½¿ç”¨ã€‚æœ€å¤§çš„å„ªé»åè€Œä¸æ˜¯ä½¿ç”¨ Numba æœ¬èº«ï¼Œè€Œæ˜¯å¯ä»¥ç°¡å–®çš„å»ºç«‹ Numpy ufunc å‡½å¼ï¼Œå› ç‚ºåŸæœ¬çš„æ–¹æ³•éœ€è¦å¯« C èªè¨€ã€‚

é€™è£¡æ˜¯ç¯„ä¾‹ï¼Œç¶²è·¯ä¸Šèªª vectorize ç›®çš„æ˜¯å¹³è¡Œè™•ç†é‚„æ˜¯å‘é‡åŒ–éƒ½æ˜¯éæ™‚çš„ï¼Œæ–‡æª”å¯«çš„å¾ˆæ¸…æ¥šï¼Œvectorize æ˜¯ç”¨ä¾†è®“å‡½å¼èƒ½ç”¨ä½œ Numpy ufunc å‡½å¼ï¼Œæ–¼æ˜¯ä½ å°±å¯ä»¥æŠŠä¸€å€‹ç°¡å–®çš„å‡½å¼æ”¹æˆåƒ numpy ä¸€æ¨£ä½¿ç”¨ï¼Œä½†æ˜¯æœ‰è‘— numba çš„é€Ÿåº¦å„ªåŒ–ã€‚æ­¤æ–¹æ³•ä¸æ¨è–¦ä½¿ç”¨ï¼Œå› ç‚ºä¸å¥½æ‡‚ï¼Œä½ çœ‹è‘—ä¸€å€‹å‡½å¼æœƒæƒ³èªªé€™æ–¹æ³•å¾å“ªä¾†çš„ï¼Œåˆ¥äººä¸å¥½ç†è§£ç¨‹å¼ç¢¼ï¼ŒIDE ä¹Ÿæœƒè·³è­¦å‘Šã€‚
```py
# Edit from: https://github.com/numba/numba/blob/main/numba/tests/doc_examples/test_examples.py
# test_vectorize_multiple_signatures
from numba import vectorize
import numpy as np

@vectorize(["int32(int32, int32)",
            "int64(int64, int64)",
            "float32(float32, float32)",
            "float64(float64, float64)"])
def f(x, y):
    return x + y

a = np.arange(6)
result = f(a, a)
# result == array([ 0,  2,  4,  6,  8, 10])

correct = np.array([0, 2, 4, 6, 8, 10])
np.testing.assert_array_equal(result, correct)

a = np.linspace(0, 1, 6)
result = f(a, a)
# Now, result == array([0. , 0.4, 0.8, 1.2, 1.6, 2. ])

correct = np.array([0., 0.4, 0.8, 1.2, 1.6, 2. ])
np.testing.assert_allclose(result, correct)

a = np.arange(12).reshape(3, 4)
# a == array([[ 0,  1,  2,  3],
#             [ 4,  5,  6,  7],
#             [ 8,  9, 10, 11]])

result1 = f.reduce(a, axis=0)
print(result1)
# result1 == array([12, 15, 18, 21])

result2 = f.reduce(a, axis=1)
print(result2)
# result2 == array([ 6, 22, 38])

result3 = f.accumulate(a)
print(result3)
# result3 == array([[ 0,  1,  2,  3],
#                   [ 4,  6,  8, 10],
#                   [12, 15, 18, 21]])

result4 = f.accumulate(a, axis=1)
print(result4)
```

#### guvectorize
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-guvectorize-decorator)

generalized universal functionsï¼Œå¼·åŒ–ç‰ˆçš„ vectorizeï¼Œå…è¨±è¼¸å…¥æ˜¯ä»»æ„æ•¸é‡çš„ ufunc å…ƒç´ ï¼Œæ¥å—ä»»æ„å½¢ç‹€è¼¸å…¥è¼¸å‡ºçš„å…ƒç´ ã€‚æ–‡æª”æ²’æœ‰ä¸¦æ²’æœ‰èªª guvectorize æœ‰ä»»ä½•æ•ˆèƒ½å„ªåŒ–ï¼Œä½†æ˜¯å¯¦éš›æ¸¬è©¦[é€™ç¯‡æ–‡ç« ](https://medium.com/capital-one-tech/dask-numba-for-efficient-in-memory-model-scoring-dfc9b68ba6ce)å¾Œç™¼ç¾ guvectorize é€Ÿåº¦ç¢ºå¯¦æ¯”è¼ƒå¿«ï¼Œä¸çŸ¥é“åŸå› æ‰€ä»¥ç¨±ä»–ç‚ºé­”æ³•ã€‚

ä¸€æ¨£æ˜¯ä¸€å€‹è£é£¾å™¨å°±å®Œæˆï¼Œé€™è£¡é™„ä¸Šä½¿ç”¨ç¯„ä¾‹

<Tabs>
  <TabItem value="1" label="å‘½åæ–¹å¼ç¤ºç¯„ï¼šçŸ©é™£ç›¸ä¹˜">
  
    ```py
    from numba import guvectorize, prange
    import numpy as np
    import time


    # vanilla guvectorize
    # tuple ç¬¬ä¸€é …è¨­å®šè¼¸å…¥
    # è¼¸å…¥ï¼šåœ¨ list ä¸­è¨­å®šé¸é …ï¼Œé€™è£¡å¯æ¥å—å››ç¨®é¡å‹çš„è¼¸å…¥
    # è¼¸å‡ºï¼šåªéœ€å®šç¾©ç¶­åº¦ (m,n),(n,p)->(m,p)
    # è¼¸å…¥ "C"ï¼šguvectorize ä¸éœ€è¦ returnï¼Œè€Œæ˜¯æŠŠå›å‚³å€¼ç›´æ¥å¯«å…¥è¼¸å…¥çŸ©é™£ C
    @guvectorize(
        [
            "float64[:,:], float64[:,:], float64[:,:]",
            "float64[:,:], float64[:,:], float64[:,:]",
            "int32[:,:], int32[:,:], int32[:,:]",
            "int64[:,:], int64[:,:], int64[:,:]",
        ],
        "(m,n),(n,p)->(m,p)",
    )
    def matrix_multiply(A, B, C):
        m, n = A.shape
        n, p = B.shape
        for i in range(m):
            for j in range(p):
                C[i, j] = 0
                for k in range(n):
                    C[i, j] += A[i, k] * B[k, j]


    # guvectorize with prange
    # æ¸¬è©¦ nopython, parallel
    @guvectorize(
        [
            "float64[:,:], float64[:,:], float64[:,:]",
            "float64[:,:], float64[:,:], float64[:,:]",
            "int32[:,:], int32[:,:], int32[:,:]",
            "int64[:,:], int64[:,:], int64[:,:]",
        ],
        "(m,n),(n,p)->(m,p)",
        nopython=True,
        target="parallel",
    )
    def matrix_multiply_prange(A, B, C):
        m, n = A.shape
        n, p = B.shape
        for i in prange(m):
            for j in range(p):
                C[i, j] = 0
                for k in range(n):
                    C[i, j] += A[i, k] * B[k, j]


    def run_benchmark():
        n_runs = 1
        N = 100
        A = np.random.rand(N, N).astype(np.float64)
        B = np.random.rand(N, N).astype(np.float64)
        res_python = A @ B

        start = time.time()
        for _ in range(n_runs):
            C = np.empty((N, N), dtype=np.float64)
            matrix_multiply(A, B, C)
            print("Are the results the same?", np.allclose(C, res_python))
        end = time.time()
        print("Without prange: Total time for {} runs: {:.4f} seconds".format(n_runs, end - start))

        start = time.time()
        for _ in range(n_runs):
            C_prange = np.empty((N, N), dtype=np.float64)
            matrix_multiply_prange(A, B, C_prange)
            print("Are the results the same?", np.allclose(C_prange, res_python))
        end = time.time()
        print("With prange: Total time for {} runs: {:.4f} seconds".format(n_runs, end - start))

    run_benchmark()

    # Are the results the same? True
    # Without prange: Total time for 1 runs: 0.0012 seconds
    # Are the results the same? True
    # With prange: Total time for 1 runs: 0.0012 seconds
    ```

  </TabItem>

  <TabItem value="2" label="æ•ˆèƒ½æ¸¬è©¦">

    ```py
    import numpy as np
    import time
    from numba import njit, guvectorize, prange

    n = 250000
    x = np.random.poisson(lam=5, size=n)
    y, z = np.random.normal(size=(n, 2)).T
    overlay = False
    n_runs = 100
    res = np.zeros((n, 15))


    # åŸå§‹Pythonç‰ˆæœ¬
    def python_func(x, y, z, overlay=False):
        out = np.zeros((x.shape[0], 15))
        adj = 1.5 if overlay else 1.0
        for t in range(15):
            out[:, t] = t * x**2 + y - 2 * z - 2 * t
        return adj * out


    # @njit å„ªåŒ–ç‰ˆæœ¬
    @njit
    def jitted_func(x, y, z, overlay=False):
        out = np.zeros((x.shape[0], 15))
        adj = 1.5 if overlay else 1.0
        for t in range(15):
            out[:, t] = t * x**2 + y - 2 * z - 2 * t
        return adj * out


    # @njit + signature å„ªåŒ–ç‰ˆæœ¬
    @njit("float64[:,:](int64[:], float64[:], float64[:], boolean)")
    def jitted_func_with_signature(x, y, z, overlay=False):
        out = np.zeros((x.shape[0], 15))
        adj = 1.5 if overlay else 1.0
        for t in range(15):
            out[:, t] = t * x**2 + y - 2 * z - 2 * t
        return adj * out


    # @guvectorize å„ªåŒ–ç‰ˆæœ¬
    @guvectorize(
        "i8, f8, f8, b1, f8[:], f8[:]",
        "(), (), (), (), (specifySameDimension) -> (specifySameDimension)",
    )
    def fast_predict_over_time(x, y, z, overlay, _, out):
        adj = 1.5 if overlay else 1.0
        for t in range(len(out)):
            out[t] = adj * (t * x**2 + y - 2 * z - 2 * t)


    # åˆå§‹åŒ–ç·¨è­¯
    res_python = python_func(x, y, z, overlay)
    res_jitted = jitted_func(x, y, z, overlay)
    res_jitted_signature = jitted_func_with_signature(x, y, z, overlay)
    res_fast_pred = fast_predict_over_time(x, y, z, overlay, res)

    # 1. æ¸¬è©¦åŸå§‹Pythonç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = python_func(x, y, z, overlay)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, pure Python")

    # 2. æ¸¬è©¦ @njit å„ªåŒ–ç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = jitted_func(x, y, z, overlay)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, pure @njit")

    # 3. æ¸¬è©¦ @njit + signature å„ªåŒ–ç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = jitted_func_with_signature(x, y, z, overlay)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, @njit with signature")

    # 4. æ¸¬è©¦ @guvectorize å„ªåŒ–ç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = fast_predict_over_time(x, y, z, overlay, res)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, @guvectorize")

    print("Are the results the same?", np.array_equal(res_python, res_fast_pred))
    print("Are the results the same?", np.array_equal(res_python, res_jitted_signature))

    # Time: 0.039077 seconds, pure Python
    # Time: 0.027496 seconds, pure @njit
    # Time: 0.027633 seconds, @njit with signature
    # Time: 0.005587 seconds, @guvectorize
    # Are the results the same? True
    # Are the results the same? True
    ```

  </TabItem>
</Tabs>
  
#### jitclass
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/jitclass.html)  

æŠŠ class ä¸­æ‰€æœ‰ methods éƒ½ç”¨ numba å„ªåŒ–ï¼Œé‚„åœ¨æ—©æœŸç‰ˆæœ¬ã€‚ä½¿ç”¨ jit class ä¸€å®šæ˜¯ nopython æ¨¡å¼ã€‚

å€‹äººæ„Ÿè¦ºä¸å¥½ç”¨ï¼Œå› ç‚ºä½ è¦çµ¦å‡º class é¡æ‰€æœ‰æˆå“¡çš„è³‡æ–™é¡å‹ï¼Œé‚„ä¸å¦‚ç›´æ¥åœ¨å¤–é¢å¯«å¥½ Numba è£é£¾çš„å‡½å¼å†åˆ° class ä¸­å®šç¾© method å‘¼å«ï¼Œé™„ä¸Š[æœ‰ä½¿ç”¨åˆ° jitclass çš„æ•™å­¸](https://curiouscoding.nl/posts/numba-cuda-speedup/)ã€‚

#### stencil
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/stencil.html)

ç”¨æ–¼ç°¡åŒ–å›ºå®šæ¨¡å¼ï¼ˆstencil kernelï¼‰é€²è¡Œçš„æ“ä½œä»¥æå‡ç¨‹å¼ç¢¼å¯è®€æ€§ï¼Œä¾‹å¦‚å°ä¸Šä¸‹å·¦å³å–å¹³å‡ï¼Œå¯ä»¥å¯«æˆå¦‚ä¸‹æ–¹å½¢å¼ï¼Œå¯è®€æ€§é«˜ï¼Œæ•ˆèƒ½ä¹Ÿå’Œ jit ä¸€æ¨£ã€‚

```py
import time
import numpy as np
from numba import stencil, njit

@stencil
def kernel1(a):
    # a ä»£è¡¨å¥—ç”¨æ ¸å¿ƒçš„è¼¸å…¥é™£åˆ—
    return 0.25 * (a[0, 1] + a[1, 0] + a[0, -1] + a[-1, 0])

@njit
def kernel1_jit(a):
    return kernel1(a)

def kernel1_python(a):
    result = np.zeros_like(a)
    for i in range(1, a.shape[0] - 1):
        for j in range(1, a.shape[1] - 1):
            result[i, j] = 0.25 * (a[i, j + 1] + a[i + 1, j] + a[i, j - 1] + a[i - 1, j])
    return result

@njit
def kernel1_python_jit(a):
    result = np.zeros_like(a)
    for i in range(1, a.shape[0] - 1):
        for j in range(1, a.shape[1] - 1):
            result[i, j] = 0.25 * (a[i, j + 1] + a[i + 1, j] + a[i, j - 1] + a[i - 1, j])
    return result


n_runs = 100
input_array = np.random.rand(5000, 5000)

# ç¬¬ä¸€æ¬¡é‹è¡Œçš„åˆå§‹åŒ–ï¼Œç¬¬äºŒæ¬¡ä»¥å¾Œæ‰æ˜¯å–®ç´”çš„åŸ·è¡Œæ™‚é–“
output_array_stencil = kernel1_jit(input_array)
output_array_python = kernel1_python_jit(input_array)

start = time.time()
for _ in range(n_runs):
    kernel1_jit(input_array)
end = time.time()
print(f"stencil: {(end - start)/n_runs} ç§’")

start = time.time()
for _ in range(n_runs):
    kernel1_python_jit(input_array)
end = time.time()
print(f"pure jit: {(end - start)/n_runs} ç§’")

# Compare the results
print("Are the outputs equal?", np.array_equal(output_array_stencil, output_array_python))

# è¼¸å‡º

# stencil: 0.03909627914428711 ç§’
# pure jit: 0.038599507808685304 ç§’
# Are the outputs equal? True
```

### æå‰ç·¨è­¯
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/pycc.html)

Numba ä¸»è¦æ˜¯ä½¿ç”¨å³æ™‚ç·¨è­¯ï¼Œä½†ä¹Ÿæ”¯æ´åƒ C èªè¨€ä¸€æ¨£æå‰ç·¨è­¯æ‰“åŒ…å¾ŒåŸ·è¡Œã€‚

- å„ªé»
    - åŸ·è¡Œæ™‚ä¸éœ€ numba å¥—ä»¶
    - æ²’æœ‰ç·¨è­¯æ™‚é–“é–‹éŠ·  
- ç¼ºé»
    - ä¸æ”¯æ´ ufuncs
    - å¿…é ˆæ˜ç¢ºæŒ‡å®šå‡½å¼ç°½å (signatures)
    - å°å‡ºçš„å‡½å¼ä¸æœƒæª¢æŸ¥å‚³éçš„åƒæ•¸é¡å‹ï¼Œèª¿ç”¨è€…éœ€æä¾›æ­£ç¢ºçš„é¡å‹ã€‚
    - AOT ç·¨è­¯ç”Ÿæˆé‡å° CPU æ¶æ§‹ç³»åˆ—çš„é€šç”¨ç¨‹å¼ç¢¼ï¼ˆå¦‚ "x86-64"ï¼‰ï¼Œè€Œ JIT ç·¨è­¯å‰‡ç”Ÿæˆé‡å°ç‰¹å®š CPU å‹è™Ÿçš„å„ªåŒ–ç¨‹å¼ç¢¼ã€‚

### jit_module
[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/jit-module.html)

é–‹ç™¼è€…ç”¨ï¼Œè®“æ•´å€‹æ¨¡çµ„çš„å‡½å¼éƒ½è‡ªå‹•è¢« jit è£é£¾ã€‚é™¤äº†å®˜æ–¹æ–‡æª”ï¼Œé€™è£¡ç¯€éŒ„ Github åŸå§‹ç¢¼ä¸­çš„è¨»è§£ï¼š

> Note that ``jit_module`` should only be called at the end of the module to be jitted. In addition, only functions which are defined in the module ``jit_module`` is called from are considered for automatic jit-wrapping.


## çµåˆåˆ†ä½ˆå¼è¨ˆç®—
å¸¸è¦‹çš„åˆ†ä½ˆå¼æœ‰ Ray å’Œ Daskï¼Œæ¯”å¦‚èªªæˆ‘å€‘å¯ä»¥çµåˆ Dask + Numba æ‰“ä¸€å¥—[çµ„åˆæ‹³](/docs/python/numba-tutorial-accelerate-python-computing#see-also)ã€‚

## å¸¸è¦‹å•é¡Œ
1. æˆ‘è¦å­¸æœƒå¯«å¹³è¡Œé‹ç®—ï¼Ÿ  
ä¸ç”¨ï¼Œç¶²è·¯ä¸Šåœ¨äº‚æ•™ï¼Œnumba æœƒè‡ªå‹•è™•ç†å¹³è¡Œé‹ç®—ï¼Œè€Œä¸”æ•ˆèƒ½æ¯”æ‰‹å¯«é‚„å¥½ã€‚

2. [å¯ä¸å¯ä»¥æŠŠå‡½å¼ç•¶åƒæ•¸çµ¦ numba å„ªåŒ–ï¼Ÿ](https://numba.readthedocs.io/en/stable/user/faq.html#can-i-pass-a-function-as-an-argument-to-a-jitted-function)  
å¯ä»¥ï¼Œä½†æ˜¯æœƒé€ æˆé¡å¤– call stack é–‹éŠ·ï¼Œè«‹è€ƒæ…®å·¥å» æ¨¡å¼ã€‚

3. æå‰ç·¨è­¯åŸ·è¡Œæ•ˆç‡æœƒè®Šé«˜å—ï¼Ÿ  
ä¸æœƒã€‚æ ¹æ“šæ–‡æª”ï¼Œæå‰ç·¨è­¯æœƒç”Ÿæˆæœ€æ³›ç”¨çš„å‡½å¼è€Œä¸æ˜¯æœ€ç¬¦åˆç•¶å‰ CPU/GPU çš„å‡½å¼ã€‚

4. Numba JIT å’Œ Python JIT ä¸€æ¨£å—ï¼Ÿ  
[ä¸ç¢ºå®š]æ ¹æ“šé€™å€‹å½±ç‰‡èªªæ˜ [CPython JIT](https://www.youtube.com/watch?v=SNXZPZA8PY8) çš„æ ¸å¿ƒç†å¿µæ˜¯ JITï¼Œè€Œç­†è€…åœ¨æ–‡æª”æˆ–è€… Numba Github repo ä¸­å®Œå…¨æœä¸åˆ°æœ‰é—œç†±é»åˆ†æçš„é—œéµå­—ï¼Œæ‡‰è©²æ˜¯ä¸ä¸€æ¨£ã€‚

5. numba å¯èƒ½æœƒç”¢ç”Ÿå’Œ Numpy ä¸ä¸€æ¨£çš„çµæœ  
æ ¹æ“š[æµ®é»é™·é˜±](https://numba.readthedocs.io/en/stable/reference/fpsemantics.html)ï¼Œæˆ‘å€‘æ‡‰è©²é¿å…å°åŒä¸€çŸ©é™£é‡è¤‡ä½¿ç”¨ numba é‹ç®—ä»¥å…è¶ŠéŒ¯è¶Šå¤šã€‚


## See Also
é€™è£¡æ”¾ç­†è€…è¦ºå¾—æœ‰ç”¨çš„æ–‡ç« ã€‚

- [å®˜æ–¹ä½¿ç”¨ç¯„ä¾‹](https://numba.readthedocs.io/en/stable/user/examples.html)
- å° Numba ç¨‹å¼ç¢¼é€²è¡Œæ•ˆèƒ½åˆ†æã€‚  
[Profiling your numba code](https://pythonspeed.com/articles/numba-profiling/)
- ğŸ”¥ é™£åˆ—é‹ç®—é™ä½ Numba é€Ÿåº¦çš„ç¯„ä¾‹  
[The wrong way to speed up your code with numba](https://pythonspeed.com/articles/slow-numba/)  
- ğŸ”¥ CUDA åŠ é€Ÿä¸¦ä¸”æœ‰å®Œæ•´çš„å°æ¯”ï¼Œå€¼å¾—ä¸€çœ‹ã€‚  
[28000x speedup with numba.CUDA](https://curiouscoding.nl/posts/numba-cuda-speedup/)   
- éå¸¸é•·çš„ CUDA æ•™å­¸æ–‡ç« ã€‚  
[ç”¨ numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸Š)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8A-ede7b381f6c7) 
- éå¸¸é•·çš„ CUDA æ•™å­¸æ–‡ç« ã€‚  
[ç”¨ numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸‹)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8B-770c11bffd37)
- ğŸ”¥ ä½¿ç”¨ Dask + Numba çš„ç°¡å–®ç¯„ä¾‹ï¼Œå…¶ä¸­åŒ…æ‹¬ guvectoize çš„ä½¿ç”¨ï¼Œå€¼å¾—ä¸€çœ‹ã€‚  
[Dask + Numba for Efficient In-Memory Model Scoring](https://medium.com/capital-one-tech/dask-numba-for-efficient-in-memory-model-scoring-dfc9b68ba6ce) 
- ä½¿ç”¨ Numba CUDA åŠŸèƒ½åŠ ä¸Š Dask åˆ†æ•£å¼åŠ é€Ÿé‹ç®—ä¸¦è§£æ±ºé¡¯å¡è¨˜æ†¶é«”ä¸è¶³çš„å•é¡Œã€‚  
[Accelerated Portfolio Construction with Numba and Dask in Python](https://developer.nvidia.com/blog/accelerated-portfolio-construction-with-numba-and-dask-in-python/)
- éœ€è¦æœ‰è¨ˆç®—æ©Ÿçµ„ç¹”çš„çŸ¥è­˜æ‰èƒ½è®€æ‡‚å¾—æ€§èƒ½å„ªåŒ–æŒ‡å—  
[How to Write Fast Numerical Code](https://people.inf.ethz.ch/markusp/teaching/263-2300-ETH-spring14/slides/06-locality-caches.pdf)

- éå®˜æ–¹[ä¸­æ–‡æ–‡æª”](https://github.com/apachecn/numba-doc-zh) åªæ›´æ–°åˆ° 0.44ï¼ŒæŒ‰éœ€è§€çœ‹ï¼ŒèˆŠç‰ˆç¼ºä¹ä½¿ç”¨è­¦å‘Šå¯èƒ½å°è‡´æ„æƒ³ä¸åˆ°çš„éŒ¯èª¤ã€‚


## é™„éŒ„
- [[å»¶ä¼¸é–±è®€](https://medium.com/citycoddee/python%E9%80%B2%E9%9A%8E%E6%8A%80%E5%B7%A7-5-python-%E5%88%B0%E5%BA%95%E6%80%8E%E9%BA%BC%E8%A2%AB%E5%9F%B7%E8%A1%8C-%E7%9B%B4%E8%AD%AF-%E7%B7%A8%E8%AD%AF-%E5%AD%97%E7%AF%80%E7%A2%BC-%E8%99%9B%E6%93%AC%E6%A9%9F%E7%9C%8B%E4%B8%8D%E6%87%82-553182101653)] Python åº•å±¤åŸ·è¡Œæ–¹å¼  
  Python å’Œ C/C++ ç·¨è­¯æˆæ©Ÿå™¨ç¢¼å¾ŒåŸ·è¡Œä¸åŒï¼Œéœ€è¦å…ˆç›´è­¯ (interprete) æˆå­—ç¯€ç¢¼ï¼Œå†ç¶“ç”±è™›æ“¬æ©Ÿä½œç‚ºä»‹é¢åŸ·è¡Œæ¯å€‹å­—ç¯€ç¢¼çš„æ©Ÿå™¨ç¢¼ï¼Œå†åŠ ä¸Šå‹•æ…‹èªè¨€éœ€è¦çš„å‹åˆ¥æª¢æŸ¥å°è‡´é€Ÿåº¦ç·©æ…¢ã€‚

- [å»¶ä¼¸é–±è®€] å…¨åŸŸç›´è­¯å™¨é– GIL  
  ç”¨ä¾†é™åˆ¶åŒä¸€æ™‚é–“å…§åªèƒ½æœ‰ä¸€å€‹åŸ·è¡Œç·’åŸ·è¡Œ Python å­—ç¯€ç¢¼çš„æ©Ÿåˆ¶ã€‚Python å…§å»ºè³‡æ–™çµæ§‹å¦‚å­—å…¸ç­‰ä¸¦éç·šç¨‹å®‰å…¨ï¼Œæ‰€ä»¥éœ€è¦ GIL ç¢ºä¿äº†å¤šåŸ·è¡Œç·’ç¨‹å¼çš„å®‰å…¨æ€§ï¼Œé¿å…ç«¶çˆ­å±å®³ï¼Œç„¶è€Œä¹Ÿå°è‡´äº†å¤šåŸ·è¡Œç·’ç¨‹å¼åœ¨å·¥ä½œä¸­çš„æ•ˆèƒ½ä½è½ã€‚
  
- AOT  
  Compilation of a function in a separate step before running the program code, producing an on-disk binary object which can be distributed independently. This is the traditional kind of compilation known in languages such as C, C++ or Fortran.

- Python bytecode ï¼ˆå­—ç¯€ç¢¼ï¼‰  
  The original form in which Python functions are executed. Python bytecode describes a stack-machine executing abstract (untyped) operations using operands from both the function stack and the execution environment (e.g. global variables).

- JIT  
  Compilation of a function at execution time, as opposed to ahead-of-time compilation.

- ufunc  
  A NumPy universal function. numba can create new compiled ufuncs with the @vectorize decorator.

- jitted
  ç¶“é JIT ç·¨è­¯å¾Œçš„ç¨‹å¼ç¢¼ç¨±åš jittedã€‚

- [å»¶ä¼¸å˜´ç ²] ç”šè‡³å¯ä»¥æ‰¾åˆ°é€™æ¨£çš„ä¸€ç¯‡è«–æ–‡ï¼šDask & Numba: Simple libraries for optimizing scientific python codeï¼Œæ•æˆ‘ç›´è¨€ï¼Œé€™æ¯”ç†Šæ–‡æ¡ˆé‚„æ°´ã€‚

## çµèª
é•·é”ä¸€è¬å­—çš„æ•™å­¸çµæŸäº†ï¼Œæ‡‰è©²ä¾†å€‹ä¸€éµä¸‰é€£å§ã€‚

ç›®æ¨™è®€è€…å…¶å¯¦å°±æ˜¯åœ¨èªªé€šè¨Šç³»ï¼Œä¹Ÿå°±æ˜¯ç•¶å¹´çš„è‡ªå·±ã€‚å¦å¤–çœ‹åˆ°åˆ¥ç¯‡æ–‡ç« çµå°¾æ„Ÿè¬éƒ¨é–€å…¶é¤˜å››å€‹äººï¼Œæ‰€ä»¥ç¸½å…±äº”å€‹äººè¨è«–å‡ºä¾†æ‰å¯«å‡º numba æ–‡ç« ï¼Œç•¶æ™‚é›–ç„¶æ¯”ä»–æ™šä¸€å¹´ï¼Œä½†ç­†è€…ç•¶å¹´å¯æ˜¯ç ”ç©¶ç”Ÿï¼Œä¸€å€‹äººè‡ªå·±å­¸æœƒç”¨ numba...å¤­å£½å¯¦é©—å®¤ã€‚

é–‹é ­çš„æœ€å¿«ã€æœ€æ­£ç¢ºå’Œæœ€å®Œæ•´ï¼Œå…¶å¯¦æ˜¯è‡ªå·±çœ‹ç¶²è·¯æ–‡ç« ä¸€ç›´ä»¥ä¾†çš„ä¸èˆ’æœæ„Ÿï¼Œå®Œæ•´çš„å¤ªè©³ç´°ï¼ˆè·Ÿè®€æ–‡æª”æ²’å…©æ¨£ï¼‰ï¼Œå¿«ä¸”æ­£ç¢ºçš„æ–‡ç« åˆä¸å®Œæ•´ï¼Œå¥½åƒæ°¸é æ²’è¾¦æ³•å…¼é¡§ã€‚æ–¼æ˜¯æœ¬æ–‡å’Œæˆ‘å¯«çš„å…¶ä»–æ•™å­¸æ–‡ç« ä¸€æ¨£ï¼Œä¸»è¦ç…§é¡§åˆå­¸è€…ï¼Œè®“åˆå­¸è€…å¯ä»¥å¿«é€Ÿä¸Šæ‰‹ï¼Œè®€èµ·ä¾†åˆå®Œæ•´ï¼Œè€Œä¸”å…§å®¹é‚„æ­£ç¢ºï¼Œç•¶è®€è€…ä¸éœ€è¦ä½¿ç”¨å¹³è¡ŒåŒ–æ™‚å¯ä»¥åœ¨ååˆ†é˜ä¹‹å…§æå®š Numbaï¼Œéœ€è¦å¹³è¡ŒåŒ–æˆ– vectorize ç­‰é«˜ç´šä½¿ç”¨æŠ€å·§æ™‚ä¹Ÿå°ç¶²è·¯ä¸Šè¨±å¤šéŒ¯èª¤åšå‡ºå‹˜èª¤å’Œå¯¦æ¸¬çµæœï¼Œæ„Ÿè¬èƒ½è®€å®Œçš„å„ä½ã€‚

>å…§å®¹åŸºæ–¼ numba æ–‡æª”ï¼Œä½œè€…ï¼šAnaconda, Inc.ï¼Œæˆæ¬Šï¼šBSD 2-Clauseã€‚
>
>- GitHub: https://github.com/numba/numba
>- æ–‡æª”: https://numba.readthedocs.io/