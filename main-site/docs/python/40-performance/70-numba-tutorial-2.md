---
title: Numba æ•™å­¸ï¼šåŠ é€Ÿ Python ç§‘å­¸è¨ˆç®—ï¼ˆä¸‹ï¼‰
description: ä½ èƒ½æ‰¾åˆ°æœ€å¥½çš„ Numba æ•™å­¸ï¼
sidebar_label: Numba æ•™å­¸ï¼ˆä¸‹ï¼‰
slug: /numba-tutorial-2
tags:
  - Python
  - Numba
  - Performance
  - æ•™å­¸
keywords:
  - Python
  - Numba
  - Performance
  - Numpy
  - æ•™å­¸
  - Speed-Up
  - Accelerate
last_update:
  date: 2024-10-18T00:00:00+08:00
  author: zsl0621
first_publish:
  date: 2024-10-18T00:00:00+08:00
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Numba æ•™å­¸ï¼šåŠ é€Ÿ Python ç§‘å­¸è¨ˆç®—ï¼ˆä¸‹ï¼‰

é™¤éä½ æ˜¯é€²éšç”¨æˆ¶ï¼Œå¦å‰‡ **ä½ ä¸æ‡‰è©²çœ‹é€²éšä½¿ç”¨ç« ç¯€ï¼** çœ‹äº†åè€Œæ¨¡ç³Šç„¦é»ï¼Œæ‡‰è©²å…ˆæŒæ¡åŸºç¤ä½¿ç”¨ï¼Œå› ç‚ºåŸºç¤ä½¿ç”¨å·²æ¶µè“‹ä¸ƒæˆä»¥ä¸Šçš„ä½¿ç”¨æƒ…å¢ƒï¼ŒåŸºç¤ä½¿ç”¨è«‹çœ‹[æ•™å­¸ä¸Šç¯‡](numba-tutorial-1)ã€‚

åªæœ‰ [ä½¿ç”¨å­—å…¸å‚³éåƒæ•¸](#dict-var) å’Œ [å‘é‡åŒ–è£é£¾å™¨](#vectorize) å¯ä»¥å…ˆå·çœ‹ã€‚

## ä½¿ç”¨ CUDA åŠ é€Ÿé‹ç®—

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/cuda/overview.html)

å„ªåŒ– CUDA ç›¸è¼ƒæ–¼é‡å° CPU å„ªåŒ–åªè¦åŠ ä¸Šè£é£¾å™¨ä¾†èªªæ›´ç‚ºè¤‡é›œï¼Œå› ç‚ºéœ€è¦å° CUDA ç‰¹åˆ¥å¯«å‡½å¼ï¼Œå°è‡´ç¨‹å¼åªèƒ½åœ¨ GPU ä¸Šè·‘ï¼Œæ‰€ä»¥ç­†è€…ç›®å‰é‚„æ²’å¯«éï¼Œä¸éåŸºæœ¬æ³¨æ„äº‹é …ä¸€æ¨£æ˜¯æ³¨æ„ IOã€å·¥ä½œé‡å¤ªå°çš„ä¸é©åˆ CUDAã€‚

<!-- é‚£æ¯”è¼ƒä»€éº¼å‡½å¼é©åˆ CPU è€Œä¸æ˜¯ CUDA å‘¢ï¼Ÿ

1. **é †åºè™•ç†è€Œä¸æ˜¯å¹³è¡Œè™•ç†**ï¼Œå½±åƒè™•ç†ä»¥å¤–çš„æ¼”ç®—æ³•å¤§æ¦‚éƒ½æ˜¯é€™é¡
2. è¨˜æ†¶é«”è¶…éé¡¯å¡è¨˜æ†¶é«”ä¸Šé™
3. å¤§é‡åˆ†æ”¯è™•ç† (if-else)
4. é¡¯å¡é›™ç²¾åº¦æµ®é»é‹ç®—æ•ˆèƒ½å·®ï¼Œæ·±åº¦å­¸ç¿’å’ŒéŠæˆ²éƒ½åƒå–®ç²¾åº¦ï¼Œä½†æ˜¯ç§‘å­¸è¨ˆç®—éœ€è¦é›™ç²¾åº¦ï¼Œè€Œæˆ‘å€‘åˆåªèƒ½è²·åˆ°éŠæˆ²å¡
5. éœ€è¦åªæ”¯æ´ CPU çš„ library

å¦‚æœä½ éœ€è¦ä½¿ç”¨ CUDAï¼Œé€™è£¡ä¹Ÿæœ‰å¥½ç”¨çš„æŒ‡å—é€£çµï¼š

- [28000x speedup with numba.CUDA](https://curiouscoding.nl/posts/numba-cuda-speedup/)ï¼šä½¿ç”¨ CUDA åŠ é€Ÿä¸¦ä¸”æœ‰å®Œæ•´çš„å°æ¯”ã€‚  
- [ç”¨ numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸Š)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8A-ede7b381f6c7)
- [ç”¨ numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸‹)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8B-770c11bffd37) -->

ç¶“éä¸€äº›ç ”ç©¶å¾Œï¼Œç­†è€…èªç‚ºä¸è©²ç”¨ Numba èª¿ç”¨ CUDAï¼Œå·¥æ¬²å–„å…¶äº‹ï¼Œæ—¢ç„¶ç¨‹å¼ç¢¼æ²’æœ‰ä¾¿æ”œæ€§ï¼Œé‚£é‚„ä¸å¦‚ç›´æ¥ç”¨å°ˆé–€å„ªåŒ– CUDA çš„å¥—ä»¶ã€‚æ ¹æ“š[æ­¤ç¯‡ reddit çš„è¨è«–](https://www.reddit.com/r/Python/comments/xausj8/options_for_gpu_accelerated_python_experiments/)å¯ä»¥çœ‹åˆ° CuPy æ˜¯ä¸€å€‹ä¸éŒ¯çš„é¸æ“‡ï¼Œæ˜¯å°ˆé–€èª¿ç”¨ CUDA çš„å¥—ä»¶ã€‚ç ”ç©¶é€”ä¸­ä¹Ÿç™¼ç¾ä¸€å€‹æ–°ç©çš„å¥—ä»¶ [Taichi](https://github.com/taichi-dev/taichi) ä¹Ÿå¯ä»¥èª¿ç”¨ CUDAï¼Œç¨å¾®çœ‹éæ–‡æª”å¾Œå…¶ç‰¹è‰²å¤§æ¦‚åœ¨å°ˆæ”»<u>ç‰©ç†ç²’å­è¨ˆç®—</u>ä»¥åŠæ”¯æ´è‡ªå‹•å¾®åˆ†ï¼Œå®˜æ–¹ä¹Ÿæœ‰[æ¸¬è©¦æ•ˆèƒ½çš„æ–‡ç« ](https://docs.taichi-lang.org/blog/taichi-compared-to-cub-cupy-numba)ï¼Œæ ¹æ“šè©²æ–‡ç« çš„æ¸¬è©¦çµæœï¼Œæˆ‘å€‘æ²’ä»€éº¼ç†ç”±ä½¿ç”¨ Numba èª¿ç”¨ CUDAã€‚

## ä½¿ç”¨å­—å…¸å‚³éåƒæ•¸{#dict-var}

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/reference/pysupported.html#typed-dict)

åœ¨æ•¸å€¼æ¨¡æ“¬ä¸­ï¼Œæˆ‘å€‘ä¸€å®šæœƒé‡åˆ°åƒæ•¸é‡è¶…å¤šçš„å•é¡Œï¼ŒNumba å…¶å¯¦æ”¯æ´[ç”¨å­—å…¸å‚³éåƒæ•¸](https://stackoverflow.com/questions/55078628/using-dictionaries-with-numba-njit-function)ã€‚

## Signature

[å®˜æ–¹æ–‡æª” + å¯ç”¨çš„ signature åˆ—è¡¨](https://numba.readthedocs.io/en/stable/reference/types.html#numbers)  

é¡¯å¼çš„å‘Šè¨´ Numba è¼¸å‡ºè¼¸å…¥å‹åˆ¥ï¼ŒæŸäº›åŠŸèƒ½å¼·åˆ¶è¦æ±‚æ¨™ç¤ºï¼Œèªæ³•æ˜¯ `list[è¼¸å‡º1(è¼¸å…¥1A, è¼¸å…¥1B), è¼¸å‡º2(è¼¸å…¥2A, è¼¸å…¥2B)]`ã€‚`float64[:]` è¡¨ç¤ºä¸€ç¶­é™£åˆ—ï¼Œ`float64[:,:]` è¡¨ç¤ºäºŒç¶­é™£åˆ—ã€‚

<details>
<summary>ç°¡å–®çš„ Numba signature ç¯„ä¾‹</summary>

```py
import numpy as np
import numba as nb


# ä½¿ç”¨é¡¯å¼ signature
@nb.jit("float64[:](float64[:], float64[:])", nopython=True)
def add_and_sqrt(x, y):
    result = np.empty_like(x)
    for i in range(len(x)):
        result[i] = np.sqrt(x[i] + y[i])
    return result


# ä¸ä½¿ç”¨é¡¯å¼ signature
@nb.jit(nopython=True)
def add_and_sqrt_no_sig(x, y):
    result = np.empty_like(x)
    for i in range(len(x)):
        result[i] = np.sqrt(x[i] + y[i])
    return result


if __name__ == "__main__":
    x = np.random.random(100000)
    y = np.random.random(100000)

    _ = add_and_sqrt(x, y)
    _ = add_and_sqrt_no_sig(x, y)

    result_with_sig = add_and_sqrt(x, y)
    result_without_sig = add_and_sqrt_no_sig(x, y)
    print(f"çµæœæ˜¯å¦ç›¸åŒ: {np.allclose(result_with_sig, result_without_sig)}")

# çµæœæ˜¯å¦ç›¸åŒ: True
```

</details>

<details>
<summary>è¤‡é›œçš„ Numba signature ç¯„ä¾‹</summary>

æ­¤ç¯„ä¾‹æ¼”ç¤ºä¸€å€‹å‡½å¼åŒ…å«å¤šå€‹è¼¸å‡ºè¼¸å…¥ï¼Œä¹Ÿæ”¯æ´å¤šç¨®è¼¸å‡ºè¼¸å…¥ç¶­åº¦ã€‚

```py
from numba import njit, float64, types
import numpy as np


@njit(
    [
        types.Tuple((float64, float64))(float64, float64),
        types.Tuple((float64[:], float64[:]))(float64[:], float64[:]),
    ]
)
def cosd(angle1, angle2):
    result1 = np.cos(np.radians(angle1))
    result2 = np.cos(np.radians(angle2))
    return result1, result2


# Test with single values
angle1 = 45.0
angle2 = 90.0
result1, result2 = cosd(angle1, angle2)
print(f"Results for single values: {result1}, {result2}")

# Test with arrays
angles1 = np.array([0.0, 45.0, 90.0])
angles2 = np.array([30.0, 60.0, 90.0])
results1, results2 = cosd(angles1, angles2)
print(f"Results for arrays:\n{results1}\n{results2}")
```

</details>

## å…¶ä»–è£é£¾å™¨

å¸¸è¦‹è£é£¾å™¨æœ‰

- vectorize
- guvectorize
- jitclass
- stencil

### vectorize

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-vectorize-decorator)

vectorize è£é£¾å™¨èªæ³•é™åˆ¶è¼¸å…¥è¼¸å‡ºå’Œæ‰€æœ‰é‹ç®—éƒ½åªèƒ½æ˜¯ç´”é‡ä¸èƒ½æ˜¯å‘é‡ï¼Œå…è¨±æŠŠç´”é‡æ“ä½œå‘é‡åŒ–ï¼Œä¸¦ä¸”å¯ä»¥æŠŠå‡½å¼ç•¶ä½œ [Numpy ufunc](http://docs.scipy.org/doc/numpy/reference/ufuncs.html) ä½¿ç”¨ã€‚å®˜æ–¹æ–‡æª”èŠ±äº†å¾ˆå¤§çš„ç¯‡å¹…åœ¨æè¿°è©²æ–¹æ³•å¯ä»¥ç°¡å–®çš„å»ºç«‹ Numpy ufunc å‡½å¼ï¼Œå› ç‚º[å‚³çµ±æ–¹æ³•](https://numpy.org/devdocs/user/c-info.ufunc-tutorial.html)éœ€è¦å¯« C èªè¨€ã€‚å°æ–¼æ•ˆèƒ½ï¼Œæ–‡æª”å¾ˆå¸¥æ°£çš„è¼•ææ·¡å¯«äº†ä¸€å¥è©±ï¼š

> Numba will generate the surrounding loop (or kernel) allowing efficient iteration over the actual inputs.

å®˜ç¶²å°å¦‚ä½•å„ªåŒ– jit å°ˆé–€å¯«äº†ä¸€ç¯‡æ–‡ç« ï¼Œå°æ–¼ vectorize çš„æ•ˆèƒ½åƒ…åƒ…å°±åªå¯«äº†é€™éº¼ä¸€å¥è©±ï¼Œçœ‹èµ·ä¾†æ­¤è£é£¾å™¨é‡é»å¥½åƒä¸æ˜¯æ“ºåœ¨æ•ˆèƒ½ä¸Šï¼Œç„¶è€Œ[æ­¤æ–‡ç« ](https://medium.com/@mflova/making-python-extremely-fast-with-numba-advanced-deep-dive-2-3-f809b43f8300)ä¸­çš„ vectorize é€Ÿåº¦æ¯”èµ· jit åˆå¿«äº† 20 å€ï¼æ ¹æ“šä»–çš„è§£é‡‹ï¼Œvectorize æœƒå‘Šè¨´é¡å¤–è¨Šæ¯çµ¦ LLVMï¼Œæ–¼æ˜¯ LLVM å°±å¯ä»¥è—‰æ­¤ä½¿ç”¨ CPU çš„å‘é‡é‹ç®—æŒ‡ä»¤é›† SIMDã€‚

ä¸‹æ–¹æ˜¯åŸºç¤èªæ³•ç¯„ä¾‹ï¼Œæ•ˆèƒ½æ¸¬è©¦æˆ‘å€‘æ”¾åˆ°ä¸‹é¢å¼·åŒ–ç‰ˆçš„ `guvectorize`ï¼š

```py
# Edit from: https://github.com/numba/numba/blob/main/numba/tests/doc_examples/test_examples.py
# test_vectorize_multiple_signatures
from numba import vectorize
import numpy as np

# æ ¼å¼æ˜¯ list[è¼¸å‡º1(è¼¸å…¥1A, è¼¸å…¥1B), è¼¸å‡º2(è¼¸å…¥2A, è¼¸å…¥2B)]
@vectorize(["int32(int32, int32)",
            "int64(int64, int64)",
            "float32(float32, float32)",
            "float64(float64, float64)"])
def f(x, y):
    return x + y   # å®šç¾©æ™‚ï¼Œå‡½å¼å…§åªèƒ½é€²è¡Œç´”é‡é‹ç®—

a = np.arange(6)
result = f(a, a)   # ä½¿ç”¨æ™‚ï¼Œå…è¨±è¼¸å…¥å‘é‡
# result == array([ 0,  2,  4,  6,  8, 10])

correct = np.array([0, 2, 4, 6, 8, 10])
np.testing.assert_array_equal(result, correct)

a = np.linspace(0, 1, 6)
result = f(a, a)
# Now, result == array([0. , 0.4, 0.8, 1.2, 1.6, 2. ])

correct = np.array([0., 0.4, 0.8, 1.2, 1.6, 2. ])
np.testing.assert_allclose(result, correct)

a = np.arange(12).reshape(3, 4)
# a == array([[ 0,  1,  2,  3],
#             [ 4,  5,  6,  7],
#             [ 8,  9, 10, 11]])

result1 = f.reduce(a, axis=0)
print(result1)
# result1 == array([12, 15, 18, 21])

result2 = f.reduce(a, axis=1)
print(result2)
# result2 == array([ 6, 22, 38])

result3 = f.accumulate(a)
print(result3)
# result3 == array([[ 0,  1,  2,  3],
#                   [ 4,  6,  8, 10],
#                   [12, 15, 18, 21]])

result4 = f.accumulate(a, axis=1)
print(result4)
```

### guvectorize

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-guvectorize-decorator)

generalized universal vectorizerï¼Œå¼·åŒ–ç‰ˆçš„ vectorizeï¼Œå…è¨±è¼¸å…¥æ˜¯ä»»æ„æ•¸é‡çš„ ufunc å…ƒç´ ï¼Œæ¥å—ä»»æ„å½¢ç‹€è¼¸å…¥è¼¸å‡ºçš„å…ƒç´ ã€‚é»‘é­”æ³•åˆä¾†äº†ï¼Œé€™è£¡å®˜æ–¹ä»èˆŠæ²’æœ‰æè¿°æ•ˆèƒ½ï¼Œç„¶è€Œ[é€™ç¯‡æ–‡ç« ](https://medium.com/@mflova/making-python-extremely-fast-with-numba-advanced-deep-dive-3-3-695440b62030)ä¸­æ¸¬è©¦ `guvectorize` ç«Ÿç„¶åˆæ›´å¿«ï¼Œæ¯” `vectorize` é‚„å¿«äº†å…­å€ã€‚

é™„ä¸Šèªæ³•ç¯„ä¾‹å’Œæ•ˆèƒ½æ¸¬è©¦

<Tabs>

  <TabItem value="1" label="èªæ³•ç¤ºç¯„">

    ```py
    # ä»¥çŸ©é™£ç›¸ä¹˜ç¤ºç¯„ guvectorize çš„èªæ³•
    from numba import guvectorize, prange
    import numpy as np
    import time


    # ç°½ç« æ ¼å¼ï¼šåœ¨ list ä¸­è¨­å®šè¼¸å…¥é¸é …ï¼Œä¾åºå¡«å¯« "è¼¸å…¥1, è¼¸å…¥2, è¼¸å‡º"ã€‚æ­¤ç¯„ä¾‹å¯æ¥å—å››ç¨®é¡å‹çš„è¼¸å…¥
    # è¼¸å‡ºè¼¸å…¥ç¶­åº¦ï¼šåªéœ€å®šç¾©ç¶­åº¦ (m,n),(n,p)->(m,p)ï¼Œä¹Ÿå¯ä»¥ç©ºç™½è¡¨ç¤ºæœªæŒ‡å®šï¼Œå‡½å¼ä¸­ä¸å¯å¯« return
    # å‡½å¼è¼¸å…¥ï¼šæœ€å¾Œä¸€é …è¼¸å…¥æ˜¯æ‡‰è©²è¦è¢«å›å‚³çš„è¨ˆç®—çµæœï¼Œguvectorize ä¸ return è€Œæ˜¯ç›´æ¥å°‡çµæœå¯«å…¥è¼¸å…¥çŸ©é™£
    @guvectorize(
        [
            "float64[:,:], float64[:,:], float64[:,:]",
            "float32[:,:], float32[:,:], float32[:,:]",
            "int64[:,:], int64[:,:], int64[:,:]",
            "int32[:,:], int32[:,:], int32[:,:]",
        ],
        "(m,n),(n,p)->(m,p)",
    )
    def matrix_multiply(A, B, C):
        m, n = A.shape
        n, p = B.shape
        for i in range(m):
            for j in range(p):
                C[i, j] = 0
                for k in range(n):
                    C[i, j] += A[i, k] * B[k, j]


    # guvectorize with prange
    # æ¸¬è©¦ nopython, parallel
    @guvectorize(
        [
            "float64[:,:], float64[:,:], float64[:,:]",
            "float64[:,:], float64[:,:], float64[:,:]",
            "int32[:,:], int32[:,:], int32[:,:]",
            "int64[:,:], int64[:,:], int64[:,:]",
        ],
        "(m,n),(n,p)->(m,p)",
        nopython=True,
        target="parallel",
    )
    def matrix_multiply_prange(A, B, C):
        m, n = A.shape
        n, p = B.shape
        for i in prange(m):
            for j in range(p):
                C[i, j] = 0
                for k in range(n):
                    C[i, j] += A[i, k] * B[k, j]


    def run_benchmark():
        n_runs = 1
        N = 100
        A = np.random.rand(N, N).astype(np.float64)
        B = np.random.rand(N, N).astype(np.float64)
        res_python = A @ B

        start = time.time()
        for _ in range(n_runs):
            C = np.empty((N, N), dtype=np.float64)
            matrix_multiply(A, B, C)
            print("Are the results the same?", np.allclose(C, res_python))
        end = time.time()
        print("Without prange: Total time for {} runs: {:.4f} seconds".format(n_runs, end - start))

        start = time.time()
        for _ in range(n_runs):
            C_prange = np.empty((N, N), dtype=np.float64)
            matrix_multiply_prange(A, B, C_prange)
            print("Are the results the same?", np.allclose(C_prange, res_python))
        end = time.time()
        print("With prange: Total time for {} runs: {:.4f} seconds".format(n_runs, end - start))

    run_benchmark()

    # Are the results the same? True
    # Without prange: Total time for 1 runs: 0.0012 seconds
    # Are the results the same? True
    # With prange: Total time for 1 runs: 0.0012 seconds
    ```

</TabItem>

<TabItem value="2" label="æ¸¬è©¦çŸ©é™£ç›¸ä¹˜">

ç¨‹å¼ç¢¼ä¾†è‡ªæ–¼ [Dask + Numba for Efficient In-Memory Model Scoring](https://medium.com/capital-one-tech/dask-numba-for-efficient-in-memory-model-scoring-dfc9b68ba6ce)ã€‚

    ```py
    # æ¸¬è©¦çŸ©é™£ç›¸ä¹˜çš„æ•ˆèƒ½
    import numpy as np
    import time
    from numba import njit, guvectorize, prange

    n = 250000
    x = np.random.poisson(lam=5, size=n)
    y, z = np.random.normal(size=(n, 2)).T
    overlay = False
    n_runs = 100
    res = np.zeros((n, 15))


    # åŸå§‹Pythonç‰ˆæœ¬
    def python_func(x, y, z, overlay=False):
        out = np.zeros((x.shape[0], 15))
        adj = 1.5 if overlay else 1.0
        for t in range(15):
            out[:, t] = t * x**2 + y - 2 * z - 2 * t
        return adj * out


    # @njit å„ªåŒ–ç‰ˆæœ¬
    @njit
    def jitted_func(x, y, z, overlay=False):
        out = np.zeros((x.shape[0], 15))
        adj = 1.5 if overlay else 1.0
        for t in range(15):
            out[:, t] = t * x**2 + y - 2 * z - 2 * t
        return adj * out


    # @njit + signature å„ªåŒ–ç‰ˆæœ¬
    @njit("float64[:,:](int64[:], float64[:], float64[:], boolean)")
    def jitted_func_with_signature(x, y, z, overlay=False):
        out = np.zeros((x.shape[0], 15))
        adj = 1.5 if overlay else 1.0
        for t in range(15):
            out[:, t] = t * x**2 + y - 2 * z - 2 * t
        return adj * out


    # @guvectorize å„ªåŒ–ç‰ˆæœ¬
    @guvectorize(
        "i8, f8, f8, b1, f8[:], f8[:]",
        "(), (), (), (), (specifySameDimension) -> (specifySameDimension)",
    )
    def fast_predict_over_time(x, y, z, overlay, _, out):
        adj = 1.5 if overlay else 1.0
        for t in range(len(out)):
            out[t] = adj * (t * x**2 + y - 2 * z - 2 * t)


    # åˆå§‹åŒ–ç·¨è­¯
    res_python = python_func(x, y, z, overlay)
    res_jitted = jitted_func(x, y, z, overlay)
    res_jitted_signature = jitted_func_with_signature(x, y, z, overlay)
    res_fast_pred = fast_predict_over_time(x, y, z, overlay, res)

    # 1. æ¸¬è©¦åŸå§‹Pythonç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = python_func(x, y, z, overlay)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, pure Python")

    # 2. æ¸¬è©¦ @njit å„ªåŒ–ç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = jitted_func(x, y, z, overlay)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, pure @njit")

    # 3. æ¸¬è©¦ @njit + signature å„ªåŒ–ç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = jitted_func_with_signature(x, y, z, overlay)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, @njit with signature")

    # 4. æ¸¬è©¦ @guvectorize å„ªåŒ–ç‰ˆæœ¬
    start_time = time.time()
    for _ in range(n_runs):
        _ = fast_predict_over_time(x, y, z, overlay, res)
    end_time = time.time()
    print(f"Time: {(end_time - start_time) / n_runs:.6f} seconds, @guvectorize")

    print("Are the results the same?", np.allclose(res_python, res_fast_pred))
    print("Are the results the same?", np.allclose(res_python, res_jitted_signature))

    # Time: 0.039077 seconds, pure Python
    # Time: 0.027496 seconds, pure @njit
    # Time: 0.027633 seconds, @njit with signature
    # Time: 0.005587 seconds, @guvectorize
    # Are the results the same? True
    # Are the results the same? True
    ```
</TabItem>

<TabItem value="3" label="æ¸¬è©¦é‚è¼¯è¿´æ­¸">

é€™æ˜¯[å®˜æ–¹æ–‡æª”çš„ç¯„ä¾‹](https://numba.readthedocs.io/en/stable/user/parallel.html#examples)ï¼Œæ–‡æª”ç›®çš„æ˜¯èªªæ˜ä½¿ç”¨ `guvectorize` æœƒæŠŠç°¡å–®çš„ç¨‹å¼ç¢¼å±•é–‹åˆ°å¾ˆè¤‡é›œï¼Œæ­¤ç¯„ä¾‹ä¸­ `guvectorize` æ¯” `njit` æ…¢ã€‚

    ```py
    # æ¸¬è©¦é‚è¼¯å›æ­¸çš„æ•ˆèƒ½
    import time
    import numpy as np
    from numba import guvectorize, njit, prange


    # Python
    def logistic_regression_py(Y, X, w, iterations):
        for i in range(iterations):
            w -= np.dot(((1.0 / (1.0 + np.exp(-Y * np.dot(X, w))) - 1.0) * Y), X)
        return w


    # njit
    @njit(parallel=True)
    def logistic_regression_njit(Y, X, w, iterations):
        for _ in prange(iterations):
            w -= np.dot(((1.0 / (1.0 + np.exp(-Y * np.dot(X, w))) - 1.0) * Y), X)
        return w


    # guvectorize
    @guvectorize(
        ["void(float64[:], float64[:,:], float64[:], int64, float64[:])"],
        "(n),(n,m),(m),()->(m)",
        nopython=True,
        target="parallel",
    )
    def logistic_regression_guvec(Y, X, w, iterations, result):
        for i in prange(iterations):
            temp = np.zeros_like(w)
            for j in range(X.shape[0]):
                dot_product = np.dot(X[j].copy(), w.copy())
                sigmoid = 1.0 / (1.0 + np.exp(-Y[j] * dot_product))
                temp += (sigmoid - 1.0) * Y[j] * X[j]
            w -= temp / X.shape[0]


    np.random.seed(0)
    Y = np.abs(np.random.randn(4000))
    X = np.abs(np.random.randn(4000, 10))
    w = np.abs(np.random.randn(10))
    iterations = 100
    n_runs = 10

    w_guvec = np.zeros_like(w)
    logistic_regression_njit(Y, X, w.copy(), iterations)
    logistic_regression_guvec(Y, X, w.copy(), iterations, w_guvec)

    start_py = time.time()
    for _ in range(n_runs):
        w_py = logistic_regression_py(Y, X, w.copy(), iterations)
    end_py = time.time()
    print(f"Time: {(end_py - start_py) / n_runs:.6f} seconds, pure Python")

    start_njit = time.time()
    for _ in range(n_runs):
        w_njit = logistic_regression_njit(Y, X, w.copy(), iterations)
    end_njit = time.time()
    print(f"Time: {(end_njit - start_njit) / n_runs:.6f} seconds, @njit+parallel")

    start_guvec = time.time()
    for _ in range(n_runs):
        logistic_regression_guvec(Y, X, w.copy(), iterations, w_guvec)
    end_guvec = time.time()
    print(f"Time: {(end_guvec - start_guvec) / n_runs:.6f} seconds, guvectorize")

    # Time: 0.027217 seconds, pure Python
    # Time: 0.017704 seconds, @njit+parallel
    # Time: 0.100319 seconds, guvectorize
    ```

</TabItem>

<TabItem value="4" label="æ¸¬è©¦è¨ˆç®—å¼§é•·">

æœ¬ç¯„ä¾‹ä¾†è‡ªæ–¼ [Python åŠ é€Ÿç¬¦æ–‡ï¼šé«˜æ•ˆèƒ½å¹³è¡Œç§‘å­¸è¨ˆç®—](https://stephlin.github.io/posts/Python/Python-speedup.html)ï¼Œè©²æ–‡ç« æ²’æœ‰ä½¿ç”¨ `guvectorize` å°±ä¸‹çµè«–äº†ï¼Œé€™è£¡å¹«ä»–è£œä¸Šå¾Œå¯ä»¥ç™¼ç¾æ•ˆèƒ½åˆå¿«äº†å°‡è¿‘**ä¸€å€‹æ•¸é‡ç´š**ï¼Œå„ªåŒ–å¾Œçš„æ•ˆèƒ½ç”šè‡³å¯èƒ½è¶…é pybind11ã€‚

    ```py
    # æ¸¬è©¦è¨ˆç®—å¼§é•·çš„æ•ˆèƒ½
    import time
    import numpy as np
    from numba import guvectorize, njit, prange


    # Python ç‰ˆæœ¬
    def arc_length_py(points: np.ndarray) -> float:
        piecewice_length = np.linalg.norm(np.diff(points, axis=0), axis=1)
        return np.sum(piecewice_length)


    # njit ç‰ˆæœ¬
    @njit(parallel=True)
    def arc_length_njit1(points: np.ndarray) -> float:
        length = 0

        for i in prange(points.shape[0] - 1):
            piecewice_length = np.sqrt(np.sum((points[i + 1] - points[i]) ** 2))
            length += piecewice_length

        return length


    # guvectorize ç‰ˆæœ¬
    @guvectorize(["void(float64[:,:], float64[:])"], "(n,m)->()", nopython=True, target='parallel')
    def arc_length_guvec(points: np.ndarray, result: np.ndarray):
        length = 0

        for i in range(points.shape[0] - 1):
            piecewice_length = 0
            for j in range(points.shape[1]):
                piecewice_length += (points[i + 1, j] - points[i, j]) ** 2
            length += np.sqrt(piecewice_length)

        result[0] = length


    # åˆå§‹åŒ–
    n_runs = 100
    n_points = 10_000_000
    points = np.random.rand(n_points, 2)
    res = np.zeros(1)
    _ = arc_length_guvec(points, res)
    _ = arc_length_njit1(points)

    start_py = time.time()
    w_py = arc_length_py(points)
    end_py = time.time()
    print(f"Time: {(end_py - start_py):.6f} seconds, pure Python")

    start_njit = time.time()
    for _ in range(n_runs):
        w_njit = arc_length_njit1(points)
    end_njit = time.time()
    print(f"Time: {(end_njit - start_njit) / n_runs:.6f} seconds, njit")

    start_guvec = time.time()
    for _ in range(n_runs):
        w_guvec = arc_length_guvec(points, res)
    end_guvec = time.time()
    print(f"Time: {(end_guvec - start_guvec) / n_runs:.6f} seconds, guvectorize")

    isclose_njit = np.allclose(w_py, w_njit)
    isclose_guvec = np.allclose(w_py, res[0])
    print("Are the results the same? njit:", isclose_njit, "guvec:", isclose_guvec)

    # Time: 0.326715 seconds, pure Python
    # Time: 0.138515 seconds, njit
    # Time: 0.017213 seconds, guvectorize
    # Are the results the same? njit: True guvec: True
    ```

</TabItem>

</Tabs>

<br/>
:::tip åƒæ•¸

guvectorize å’Œ vectorize çš„ parallel èªæ³•æ˜¯ `target="option"`ï¼Œé¸é …æœ‰ cpu, parallel å’Œ cuda ä¸‰ç¨®ã€‚

å¦‚æœæ¸¬è©¦æ•¸æ“šå¤ªå° parallel å’Œ cuda æ€§èƒ½åè€Œæœƒä¸‹é™ï¼Œå› ç‚ºæ‰å‰›æ¬æ±è¥¿åˆ°è¨˜æ†¶é«”å°±çµæŸäº†ã€‚å®˜æ–¹çµ¦å‡ºçš„å»ºè­°æ˜¯ä½¿ç”¨ parallel æ•¸æ“šè‡³å°‘å¤§æ–¼ 1KBï¼Œè‡³æ–¼ cuda é‚£è‚¯å®šè¦å†å¤§æ›´å¤šã€‚

:::

### jitclass

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/jitclass.html)  

æŠŠ class ä¸­æ‰€æœ‰ methods éƒ½ç”¨ Numba å„ªåŒ–ï¼Œé‚„åœ¨å¯¦é©—ç‰ˆæœ¬ã€‚

å€‹äººèªç‚ºé€™ç¨®æ–¹æ³•ä¸å¤ªå¥½ç”¨ï¼Œå› ç‚ºéœ€è¦æ˜ç¢ºæŒ‡å®š class ä¸­æ‰€æœ‰æˆå“¡çš„è³‡æ–™é¡å‹ã€‚ä¸å¦‚ç›´æ¥åœ¨å¤–é¢å¯«å¥½ Numba è£é£¾çš„å‡½å¼ï¼Œç„¶å¾Œåœ¨ class ä¸­å®šç¾©æ–¹æ³•ä¾†èª¿ç”¨æœƒæ›´ç°¡å–®ï¼Œé™„ä¸Š[æœ‰ä½¿ç”¨åˆ° jitclass çš„æ•™å­¸](https://curiouscoding.nl/posts/numba-cuda-speedup/)ã€‚

### stencil

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/stencil.html)

ç”¨æ–¼å›ºå®šæ¨¡å¼ï¼ˆstencil kernelï¼‰çš„é‹ç®—ä»¥ç°¡åŒ–ç¨‹å¼ç¢¼ï¼Œä¾‹å¦‚å°ä¸Šä¸‹å·¦å³å–å¹³å‡ï¼Œå¯ä»¥å¯«æˆå¦‚ä¸‹æ–¹å½¢å¼ï¼Œå¯è®€æ€§é«˜ï¼Œå°ˆæœ‰åè©ä¼¼ä¹å«åš stencil computingã€‚

```py
import time
import numpy as np
from numba import stencil, njit

@stencil
def kernel1(a):
    # a ä»£è¡¨å¥—ç”¨æ ¸å¿ƒçš„è¼¸å…¥é™£åˆ—
    return 0.25 * (a[0, 1] + a[1, 0] + a[0, -1] + a[-1, 0])

@njit
def kernel1_jit(a):
    return kernel1(a)

def kernel1_python(a):
    result = np.zeros_like(a)
    for i in range(1, a.shape[0] - 1):
        for j in range(1, a.shape[1] - 1):
            result[i, j] = 0.25 * (a[i, j + 1] + a[i + 1, j] + a[i, j - 1] + a[i - 1, j])
    return result

@njit
def kernel1_python_jit(a):
    result = np.zeros_like(a)
    for i in range(1, a.shape[0] - 1):
        for j in range(1, a.shape[1] - 1):
            result[i, j] = 0.25 * (a[i, j + 1] + a[i + 1, j] + a[i, j - 1] + a[i - 1, j])
    return result


n_runs = 100
input_array = np.random.rand(5000, 5000)

# ç¬¬ä¸€æ¬¡é‹è¡Œçš„åˆå§‹åŒ–ï¼Œç¬¬äºŒæ¬¡ä»¥å¾Œæ‰æ˜¯å–®ç´”çš„åŸ·è¡Œæ™‚é–“
output_array_stencil = kernel1_jit(input_array)
output_array_python = kernel1_python_jit(input_array)

start = time.time()
for _ in range(n_runs):
    kernel1_jit(input_array)
end = time.time()
print(f"stencil: {(end - start)/n_runs} ç§’")

start = time.time()
for _ in range(n_runs):
    kernel1_python_jit(input_array)
end = time.time()
print(f"pure jit: {(end - start)/n_runs} ç§’")

# Compare the results
print("Are the outputs equal?", np.array_equal(output_array_stencil, output_array_python))

# è¼¸å‡º

# stencil: 0.03909627914428711 ç§’
# pure jit: 0.038599507808685304 ç§’
# Are the outputs equal? True
```

#### overload

[å®˜æ–¹æ–‡æª”](https://numba.pydata.org/numba-doc/dev/extending/overloading-guide.html)

é™¤äº†æ‰‹åˆ»ä¸æ”¯æ´çš„å‡½å¼ä»¥å¤–ï¼ŒNumba æä¾›äº†ä¸€å€‹é«˜éšæ–¹å¼è®“ä½ æ›¿ä»£ä¸æ”¯æ´çš„å‡½å¼ï¼Œå®˜æ–¹ç¯„ä¾‹æ˜¯ä½¿ç”¨ `@overload(scipy.linalg.norm)` æ›¿ä»£ `scipy.linalg.norm`ï¼Œç¯„ä¾‹ä¸­ä½¿ç”¨æ‰‹åˆ»çš„ `_oneD_norm_2` å¯¦ç¾ç¯„æ•¸çš„å¯¦ä½œã€‚

é€™å€‹è£é£¾å™¨åƒä»–çš„åå­—ä¸€æ¨£ç”¨æ–¼é‡è¼‰æ•´å€‹å‡½å¼ï¼Œç”¨æ–¼ä¿®æ”¹åŸæœ¬çš„å‡½å¼å…§å®¹ï¼Œæ˜¯å¾ˆé«˜éšçš„ä½¿ç”¨æ–¹å¼ï¼Œé™¤éå¿…è¦ä¸å»ºè­°ä½¿ç”¨ï¼Œæœƒå¤§å¹…å¢åŠ ç¨‹å¼ç¶­è­·é›£åº¦ã€‚

## ç·šç¨‹è¨­å®š

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/threading-layer.html)

Numba å¯ä»¥è¨­å®š threading layer ä½¿ç”¨å“ªç¨®æ–¹å¼ç®¡ç†ï¼Œæœ‰ä»¥ä¸‹å››ç¨®é¸é …ï¼š

- `default` provides no specific safety guarantee and is the default.
- `safe` is both fork and thread safe, this requires the tbb package (Intel TBB libraries) to be installed.
- `forksafe` provides a fork safe library.
- `threadsafe` provides a thread safe library.
<br/>

```py
# è¨­å®šåªä½¿ç”¨å…©å€‹ç·šç¨‹åŸ·è¡Œï¼Œæ­¤æŒ‡ä»¤ç­‰æ•ˆæ–¼ NUMBA_NUM_THREADS=2
# å®˜æ–¹æ–‡æª”èªªæ˜ï¼šåœ¨æŸäº›æƒ…å½¢ä¸‹æ‡‰è©²è¨­å®šç‚ºè¼ƒä½çš„å€¼ï¼Œä»¥ä¾¿ numba å¯ä»¥èˆ‡æ›´é«˜å±¤ç´šçš„å¹³è¡Œæ€§ä¸€èµ·ä½¿ç”¨ï¼ˆä½†æ˜¯æ–‡æª”æ²’æœ‰èªªæ˜¯å“ªäº›æƒ…å½¢ï¼‰
set_num_threads(2)
sen: %s" % threading_layer())
```

## æå‰ç·¨è­¯

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/pycc.html)

Numba ä¸»è¦æ˜¯ä½¿ç”¨å³æ™‚ç·¨è­¯ï¼Œä½†ä¹Ÿæ”¯æ´åƒ C èªè¨€ä¸€æ¨£æå‰ç·¨è­¯æ‰“åŒ…å¾ŒåŸ·è¡Œã€‚

- å„ªé»
  - åŸ·è¡Œæ™‚ä¸éœ€ Numba å¥—ä»¶ã€‚
  - æ²’æœ‰ç·¨è­¯æ™‚é–“é–‹éŠ·ã€‚  
- ç¼ºé»
  - ä¸æ”¯æ´ ufuncã€‚
  - å¿…é ˆæ˜ç¢ºæŒ‡å®šå‡½å¼ç°½å (signatures)ã€‚
  - å°å‡ºçš„å‡½å¼ä¸æœƒæª¢æŸ¥å‚³éçš„åƒæ•¸é¡å‹ï¼Œèª¿ç”¨è€…éœ€æä¾›æ­£ç¢ºçš„é¡å‹ã€‚
  - AOT ç·¨è­¯ç”Ÿæˆé‡å° CPU æ¶æ§‹ç³»åˆ—çš„é€šç”¨ç¨‹å¼ç¢¼ï¼ˆå¦‚ "x86-64"ï¼‰ï¼Œè€Œ JIT ç·¨è­¯å‰‡ç”Ÿæˆé‡å°ç‰¹å®š CPU å‹è™Ÿçš„å„ªåŒ–ç¨‹å¼ç¢¼ã€‚

## jit_module

[å®˜æ–¹æ–‡æª”](https://numba.readthedocs.io/en/stable/user/jit-module.html)

é–‹ç™¼è€…ç”¨ï¼Œè®“æ•´å€‹æ¨¡çµ„çš„å‡½å¼éƒ½è‡ªå‹•è¢« jit è£é£¾ã€‚é™¤äº†å®˜æ–¹æ–‡æª”ï¼Œé€™è£¡ç¯€éŒ„ Github åŸå§‹ç¢¼ä¸­çš„è¨»è§£ï¼š

> Note that ``jit_module`` should only be called at the end of the module to be jitted. In addition, only functions which are defined in the module ``jit_module`` is called from are considered for automatic jit-wrapping.

## çµåˆåˆ†ä½ˆå¼è¨ˆç®—

å¸¸è¦‹çš„åˆ†ä½ˆå¼å·¥å…·æœ‰ Ray å’Œ Daskï¼Œæ¯”å¦‚èªªæˆ‘å€‘å¯ä»¥çµåˆ Dask + Numba æ‰“ä¸€å¥—çµ„åˆæ‹³ï¼Œä¾‹å¦‚

- [è³‡æ–™å±¤ç´šçš„å¹³è¡ŒåŒ–è™•ç†](https://blog.dask.org/2019/04/09/numba-stencil)ï¼Œä¹ŸåŒ…å« stencil ç¯„ä¾‹ã€‚
- [æ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨é‡](https://medium.com/capital-one-tech/dask-numba-for-efficient-in-memory-model-scoring-dfc9b68ba6ce)ã€‚

## See Also

é€™è£¡æ”¾ç­†è€…è¦ºå¾—æœ‰ç”¨çš„æ–‡ç« ã€‚

- [å®˜æ–¹ä½¿ç”¨ç¯„ä¾‹](https://numba.readthedocs.io/en/stable/user/examples.html)
- ğŸ”¥ğŸ”¥ğŸ”¥ **éå¸¸å„ªè³ªçš„é€£çºŒä¸‰ç¯‡ç³»åˆ—æ–‡ç« ï¼Œä½ æœ€å¥½æŠŠé€™è£¡å…¨éƒ¨çœ‹éï¼**  
[Making Python extremely fast with Numba: Advanced Deep Dive (1/3)](https://medium.com/@mflova/making-python-extremely-fast-with-numba-advanced-deep-dive-1-3-4d303edeede4)  
[Making Python extremely fast with Numba: Advanced Deep Dive (2/3)](https://medium.com/@mflova/making-python-extremely-fast-with-numba-advanced-deep-dive-2-3-f809b43f8300)  
[Making Python extremely fast with Numba: Advanced Deep Dive (3/3)](https://medium.com/@mflova/making-python-extremely-fast-with-numba-advanced-deep-dive-3-3-695440b62030)  
- ğŸ”¥ å° Numba ç¨‹å¼ç¢¼é€²è¡Œæ•ˆèƒ½åˆ†æã€‚  
[Profiling your Numba code](https://pythonspeed.com/articles/numba-profiling/)
- ğŸ”¥ é™£åˆ—é‹ç®—é™ä½ Numba é€Ÿåº¦çš„ç¯„ä¾‹ã€‚  
[The wrong way to speed up your code with numba](https://pythonspeed.com/articles/slow-numba/)  
- ğŸ”¥ åˆ†æ”¯é æ¸¬å¦‚ä½•é™ä½ç¨‹å¼ç¢¼é€Ÿåº¦ï¼Œä»¥å¼·è¿«å¯«å…¥è§£æ±ºã€‚  
[Understanding CPUs can help speed up Numba and NumPy code](https://pythonspeed.com/articles/speeding-up-numba/)
- å½±åƒè™•ç†æ¼”ç®—æ³•çš„å„ªåŒ–ï¼šå¾åŸºç¤å¯¦ç¾é–‹å§‹  
[Speeding up your code when multiple cores arenâ€™t an option](https://pythonspeed.com/articles/optimizing-dithering/)
- ç‚ºæ¯å€‹ç·šç¨‹å»ºç«‹ local storage ä»¥æå‡æ•ˆèƒ½  
[Tips for optimising parallel numba code](https://chryswoods.com/accelerating_python/numba_bonus.html)
- ğŸ”¥ CUDA åŠ é€Ÿä¸¦ä¸”æœ‰å®Œæ•´çš„å°æ¯”ï¼Œå€¼å¾—ä¸€çœ‹ã€‚  
[28000x speedup with Numba.CUDA](https://curiouscoding.nl/posts/numba-cuda-speedup/)
- éå¸¸é•·çš„ CUDA æ•™å­¸æ–‡ç« ã€‚  
[ç”¨ Numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸Š)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8A-ede7b381f6c7)
- éå¸¸é•·çš„ CUDA æ•™å­¸æ–‡ç« ã€‚  
[ç”¨ Numba å­¸ CUDA! å¾å…¥é–€åˆ°ç²¾é€š (ä¸‹)](https://medium.com/@spacetime0311/%E7%94%A8-numba-%E5%AD%B8-cuda-%E5%BE%9E%E5%85%A5%E9%96%80%E5%88%B0%E7%B2%BE%E9%80%9A-%E4%B8%8B-770c11bffd37)
- ä½¿ç”¨ Dask + Numba çš„ç°¡å–®ç¯„ä¾‹ï¼Œå…¶ä¸­åŒ…æ‹¬ guvectoize çš„ä½¿ç”¨ã€‚  
[Dask + Numba for Efficient In-Memory Model Scoring](https://medium.com/capital-one-tech/dask-numba-for-efficient-in-memory-model-scoring-dfc9b68ba6ce)
- ä½¿ç”¨ Numba CUDA åŠŸèƒ½åŠ ä¸Š Dask åˆ†æ•£å¼åŠ é€Ÿé‹ç®—ä¸¦è§£æ±ºé¡¯å¡è¨˜æ†¶é«”ä¸è¶³çš„å•é¡Œã€‚  
[Accelerated Portfolio Construction with Numba and Dask in Python](https://developer.nvidia.com/blog/accelerated-portfolio-construction-with-numba-and-dask-in-python/)
- éœ€è¦æœ‰è¨ˆç®—æ©Ÿçµ„ç¹”çš„çŸ¥è­˜æ‰èƒ½è®€æ‡‚å¾—æ€§èƒ½å„ªåŒ–æŒ‡å—  
[How to Write Fast Numerical Code](https://people.inf.ethz.ch/markusp/teaching/263-2300-ETH-spring14/slides/06-locality-caches.pdf)

- éå®˜æ–¹[ä¸­æ–‡æ–‡æª”](https://github.com/apachecn/numba-doc-zh) åªæ›´æ–°åˆ° 0.44ï¼ŒæŒ‰éœ€è§€çœ‹ï¼ŒèˆŠç‰ˆç¼ºä¹ä½¿ç”¨è­¦å‘Šå¯èƒ½å°è‡´æ„æƒ³ä¸åˆ°çš„éŒ¯èª¤ã€‚

## çµèª

é•·é”ä¸€è¬å­—çš„æ•™å­¸çµæŸäº†ï¼ŒMarkdown ç¸½å­—æ•¸è¶…éä¸‰è¬ï¼Œæ‡‰è©²ä¾†å€‹ä¸€éµä¸‰é€£å§ã€‚

ç›®æ¨™è®€è€…å…¶å¯¦å°±æ˜¯åœ¨èªªé€šè¨Šç³»ï¼Œä¹Ÿå°±æ˜¯ç•¶å¹´çš„è‡ªå·±ã€‚

é–‹é ­çš„æœ€å¿«ã€æœ€æ­£ç¢ºå’Œæœ€å®Œæ•´ï¼Œå…¶å¯¦æ˜¯è‡ªå·±çœ‹ç¶²è·¯æ–‡ç« ä¸€ç›´ä»¥ä¾†çš„æ„Ÿå—åˆ°çš„å•é¡Œï¼Œå®Œæ•´çš„å¤ªè©³ç´°ï¼ˆè·Ÿè®€æ–‡æª”æ²’å…©æ¨£ï¼‰ï¼Œå¿«ä¸”æ­£ç¢ºçš„æ–‡ç« åˆä¸å®Œæ•´ï¼Œå¥½åƒæ°¸é æ²’è¾¦æ³•å…¼é¡§ã€‚æ–¼æ˜¯æœ¬æ–‡å’Œæˆ‘å¯«çš„å…¶ä»–æ•™å­¸æ–‡ç« ä¸€æ¨£ï¼Œä¸»è¦ç…§é¡§åˆå­¸è€…ï¼Œè®“åˆå­¸è€…å¯ä»¥å¿«é€Ÿä¸Šæ‰‹ï¼Œè®€èµ·ä¾†åˆå®Œæ•´ï¼Œè€Œä¸”å…§å®¹é‚„æ­£ç¢ºï¼Œç•¶è®€è€…ä¸éœ€è¦ä½¿ç”¨å¹³è¡ŒåŒ–æ™‚å¯ä»¥åœ¨ååˆ†é˜ä¹‹å…§æå®š Numbaï¼Œéœ€è¦å¹³è¡ŒåŒ–æˆ– vectorize ç­‰é«˜ç´šä½¿ç”¨æŠ€å·§æ™‚ä¹Ÿå°ç¶²è·¯ä¸Šè¨±å¤šéŒ¯èª¤åšå‡ºå‹˜èª¤å’Œå¯¦æ¸¬çµæœã€‚

>å…§å®¹åŸºæ–¼ Numba æ–‡æª”ï¼Œä½œè€…ï¼šAnaconda, Inc.ï¼Œæˆæ¬Šï¼šBSD 2-Clauseã€‚
>
>- GitHub: https://github.com/numba/numba
>- æ–‡æª”: https://numba.readthedocs.io/
